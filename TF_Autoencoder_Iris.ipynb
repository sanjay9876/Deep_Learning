{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C5_Autoencoder_Iris.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sV_h4l-f818"
      },
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data[:,:4]\n",
        "y = iris.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJBjlP0RhigP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "61f602d5-be50-4e95-f2b1-12209b71b161"
      },
      "source": [
        "print(X[0:10])\n",
        "print(y[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]]\n",
            "[0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gJ9eUoxhn3I"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test = train_test_split(X,shuffle=True,test_size=0.33,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM3yqAo0lCbo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c5eebe0-ed64-4ecd-ca21-5dc74e009b33"
      },
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.callbacks import TensorBoard"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWRk93L7lCtu"
      },
      "source": [
        "# this is the size of our encoded representations\n",
        "encoding_dim = 2\n",
        "input_dim = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA-vYgGklC02"
      },
      "source": [
        "# this is our input placeholder\n",
        "input_img = Input(shape=(input_dim,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = Dense(encoding_dim)(input_img)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = Dense(input_dim)(encoded)\n",
        "\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# this model maps an input to its encoded representation\n",
        "encoder = Model(input_img, encoded)\n",
        "\n",
        "# create a placeholder for an encoded (2-dimensional) input\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "# retrieve the last layer of the autoencoder model\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "# create the decoder model\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhHYPGLzlC5m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b1b920a-5830-4878-b122-1cb063247a24"
      },
      "source": [
        "autoencoder.compile(loss='mean_squared_error', optimizer='sgd')\n",
        "autoencoder.fit(X_train, X_train,\n",
        "                epochs=500,\n",
        "                batch_size=135,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_test, X_test),\n",
        "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 100 samples, validate on 50 samples\n",
            "Epoch 1/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 37.7025 - val_loss: 9.9688\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 0s 364us/step - loss: 10.3554 - val_loss: 6.8363\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 0s 41us/step - loss: 7.0932 - val_loss: 5.0521\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 0s 41us/step - loss: 5.2351 - val_loss: 3.8139\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 0s 47us/step - loss: 3.9456 - val_loss: 2.9045\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 0s 48us/step - loss: 2.9983 - val_loss: 2.2345\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 0s 46us/step - loss: 2.3003 - val_loss: 1.7482\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 0s 43us/step - loss: 1.7935 - val_loss: 1.4013\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 0s 41us/step - loss: 1.4319 - val_loss: 1.1570\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 0s 47us/step - loss: 1.1772 - val_loss: 0.9861\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 0s 42us/step - loss: 0.9989 - val_loss: 0.8662\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 0s 35us/step - loss: 0.8738 - val_loss: 0.7811\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 0s 43us/step - loss: 0.7850 - val_loss: 0.7196\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 0s 47us/step - loss: 0.7208 - val_loss: 0.6738\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 0s 43us/step - loss: 0.6730 - val_loss: 0.6385\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 0s 46us/step - loss: 0.6362 - val_loss: 0.6103\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 0s 40us/step - loss: 0.6069 - val_loss: 0.5868\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 0s 39us/step - loss: 0.5825 - val_loss: 0.5666\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 0s 41us/step - loss: 0.5617 - val_loss: 0.5488\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 0s 39us/step - loss: 0.5433 - val_loss: 0.5326\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 0s 48us/step - loss: 0.5266 - val_loss: 0.5176\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 0s 46us/step - loss: 0.5113 - val_loss: 0.5036\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 0s 47us/step - loss: 0.4969 - val_loss: 0.4904\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 0s 34us/step - loss: 0.4834 - val_loss: 0.4778\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 0s 38us/step - loss: 0.4706 - val_loss: 0.4658\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 0s 45us/step - loss: 0.4583 - val_loss: 0.4542\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 0s 54us/step - loss: 0.4466 - val_loss: 0.4432\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 0s 45us/step - loss: 0.4353 - val_loss: 0.4325\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 0s 46us/step - loss: 0.4244 - val_loss: 0.4222\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 0s 40us/step - loss: 0.4140 - val_loss: 0.4122\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 0s 51us/step - loss: 0.4039 - val_loss: 0.4026\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 0s 63us/step - loss: 0.3941 - val_loss: 0.3933\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 0s 65us/step - loss: 0.3847 - val_loss: 0.3843\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 0s 109us/step - loss: 0.3756 - val_loss: 0.3756\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.3668 - val_loss: 0.3671\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 0s 72us/step - loss: 0.3582 - val_loss: 0.3590\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 0s 52us/step - loss: 0.3500 - val_loss: 0.3510\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 0s 41us/step - loss: 0.3419 - val_loss: 0.3434\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.3342 - val_loss: 0.3359\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 0s 71us/step - loss: 0.3266 - val_loss: 0.3287\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 0s 45us/step - loss: 0.3193 - val_loss: 0.3216\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 0s 64us/step - loss: 0.3122 - val_loss: 0.3148\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 0s 56us/step - loss: 0.3053 - val_loss: 0.3082\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 0s 50us/step - loss: 0.2987 - val_loss: 0.3018\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 0s 46us/step - loss: 0.2922 - val_loss: 0.2955\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 0s 74us/step - loss: 0.2859 - val_loss: 0.2894\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 0s 37us/step - loss: 0.2797 - val_loss: 0.2835\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 0s 120us/step - loss: 0.2738 - val_loss: 0.2778\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 0s 56us/step - loss: 0.2680 - val_loss: 0.2722\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 0s 58us/step - loss: 0.2623 - val_loss: 0.2667\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 0s 50us/step - loss: 0.2569 - val_loss: 0.2615\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 0s 53us/step - loss: 0.2515 - val_loss: 0.2563\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 0s 74us/step - loss: 0.2463 - val_loss: 0.2513\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 0s 80us/step - loss: 0.2413 - val_loss: 0.2464\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 0s 65us/step - loss: 0.2364 - val_loss: 0.2416\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 0s 44us/step - loss: 0.2316 - val_loss: 0.2370\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 0s 48us/step - loss: 0.2269 - val_loss: 0.2325\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.2224 - val_loss: 0.2281\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 0s 94us/step - loss: 0.2180 - val_loss: 0.2238\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 0s 91us/step - loss: 0.2136 - val_loss: 0.2196\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 0s 54us/step - loss: 0.2094 - val_loss: 0.2155\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 0s 61us/step - loss: 0.2054 - val_loss: 0.2116\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.2014 - val_loss: 0.2077\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 0s 66us/step - loss: 0.1975 - val_loss: 0.2039\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 0s 61us/step - loss: 0.1937 - val_loss: 0.2002\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.1900 - val_loss: 0.1967\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 0s 72us/step - loss: 0.1864 - val_loss: 0.1932\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 0s 75us/step - loss: 0.1829 - val_loss: 0.1897\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 0s 47us/step - loss: 0.1795 - val_loss: 0.1864\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 0s 77us/step - loss: 0.1762 - val_loss: 0.1832\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 0s 49us/step - loss: 0.1729 - val_loss: 0.1800\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 0s 61us/step - loss: 0.1697 - val_loss: 0.1769\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 0s 75us/step - loss: 0.1667 - val_loss: 0.1739\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 0s 68us/step - loss: 0.1636 - val_loss: 0.1709\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 0s 47us/step - loss: 0.1607 - val_loss: 0.1681\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 0s 38us/step - loss: 0.1578 - val_loss: 0.1652\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 0s 52us/step - loss: 0.1550 - val_loss: 0.1625\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 0s 58us/step - loss: 0.1523 - val_loss: 0.1598\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 0s 72us/step - loss: 0.1496 - val_loss: 0.1572\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 0s 37us/step - loss: 0.1470 - val_loss: 0.1547\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 0s 63us/step - loss: 0.1445 - val_loss: 0.1522\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 0s 74us/step - loss: 0.1420 - val_loss: 0.1498\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 0s 54us/step - loss: 0.1396 - val_loss: 0.1474\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 0s 42us/step - loss: 0.1372 - val_loss: 0.1451\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 0s 46us/step - loss: 0.1349 - val_loss: 0.1428\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 0s 52us/step - loss: 0.1327 - val_loss: 0.1406\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 0s 58us/step - loss: 0.1305 - val_loss: 0.1385\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 0s 49us/step - loss: 0.1284 - val_loss: 0.1364\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.1263 - val_loss: 0.1343\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 0s 62us/step - loss: 0.1243 - val_loss: 0.1323\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 0s 72us/step - loss: 0.1223 - val_loss: 0.1303\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 0s 49us/step - loss: 0.1203 - val_loss: 0.1284\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 0s 66us/step - loss: 0.1184 - val_loss: 0.1265\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 0s 61us/step - loss: 0.1166 - val_loss: 0.1247\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.1148 - val_loss: 0.1229\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 0s 73us/step - loss: 0.1130 - val_loss: 0.1212\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 0s 74us/step - loss: 0.1113 - val_loss: 0.1195\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 0s 68us/step - loss: 0.1096 - val_loss: 0.1178\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 0s 65us/step - loss: 0.1080 - val_loss: 0.1162\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 0s 51us/step - loss: 0.1064 - val_loss: 0.1146\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 0s 51us/step - loss: 0.1048 - val_loss: 0.1131\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 0s 37us/step - loss: 0.1033 - val_loss: 0.1116\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 0s 85us/step - loss: 0.1018 - val_loss: 0.1101\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 0s 46us/step - loss: 0.1004 - val_loss: 0.1086\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 0s 56us/step - loss: 0.0990 - val_loss: 0.1072\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 0s 65us/step - loss: 0.0976 - val_loss: 0.1059\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 0s 57us/step - loss: 0.0962 - val_loss: 0.1045\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 0s 41us/step - loss: 0.0949 - val_loss: 0.1032\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 0s 52us/step - loss: 0.0936 - val_loss: 0.1019\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 0s 37us/step - loss: 0.0924 - val_loss: 0.1007\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 0s 64us/step - loss: 0.0912 - val_loss: 0.0994\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 0s 33us/step - loss: 0.0900 - val_loss: 0.0982\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 0s 91us/step - loss: 0.0888 - val_loss: 0.0971\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 0s 49us/step - loss: 0.0876 - val_loss: 0.0959\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 0s 35us/step - loss: 0.0865 - val_loss: 0.0948\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 0s 49us/step - loss: 0.0854 - val_loss: 0.0937\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 0s 43us/step - loss: 0.0844 - val_loss: 0.0926\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 0s 49us/step - loss: 0.0833 - val_loss: 0.0916\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 0s 41us/step - loss: 0.0823 - val_loss: 0.0906\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 0s 53us/step - loss: 0.0813 - val_loss: 0.0896\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 0s 51us/step - loss: 0.0804 - val_loss: 0.0886\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 0s 49us/step - loss: 0.0794 - val_loss: 0.0876\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 0s 72us/step - loss: 0.0785 - val_loss: 0.0867\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0776 - val_loss: 0.0858\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 0s 42us/step - loss: 0.0767 - val_loss: 0.0849\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 0s 64us/step - loss: 0.0759 - val_loss: 0.0840\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 0s 69us/step - loss: 0.0750 - val_loss: 0.0832\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 0s 52us/step - loss: 0.0742 - val_loss: 0.0823\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.0734 - val_loss: 0.0815\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 0s 58us/step - loss: 0.0726 - val_loss: 0.0807\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0719 - val_loss: 0.0800\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0711 - val_loss: 0.0792\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 0s 41us/step - loss: 0.0704 - val_loss: 0.0784\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 0s 89us/step - loss: 0.0697 - val_loss: 0.0777\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 0s 61us/step - loss: 0.0690 - val_loss: 0.0770\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 0s 39us/step - loss: 0.0683 - val_loss: 0.0763\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 0s 60us/step - loss: 0.0676 - val_loss: 0.0756\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 0s 45us/step - loss: 0.0670 - val_loss: 0.0750\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 0s 53us/step - loss: 0.0663 - val_loss: 0.0743\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 0s 84us/step - loss: 0.0657 - val_loss: 0.0737\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 0s 46us/step - loss: 0.0651 - val_loss: 0.0730\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 0s 75us/step - loss: 0.0645 - val_loss: 0.0724\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 0s 52us/step - loss: 0.0640 - val_loss: 0.0718\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.0634 - val_loss: 0.0712\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0628 - val_loss: 0.0707\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 0s 91us/step - loss: 0.0623 - val_loss: 0.0701\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 0s 58us/step - loss: 0.0618 - val_loss: 0.0696\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 0s 58us/step - loss: 0.0612 - val_loss: 0.0690\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 0s 70us/step - loss: 0.0607 - val_loss: 0.0685\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 0s 57us/step - loss: 0.0602 - val_loss: 0.0680\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 0s 47us/step - loss: 0.0598 - val_loss: 0.0675\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.0593 - val_loss: 0.0670\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 0s 72us/step - loss: 0.0588 - val_loss: 0.0665\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 0s 70us/step - loss: 0.0584 - val_loss: 0.0660\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 0s 61us/step - loss: 0.0579 - val_loss: 0.0656\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 0s 45us/step - loss: 0.0575 - val_loss: 0.0651\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 0s 60us/step - loss: 0.0571 - val_loss: 0.0647\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0567 - val_loss: 0.0642\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.0563 - val_loss: 0.0638\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 0s 64us/step - loss: 0.0559 - val_loss: 0.0634\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 0s 70us/step - loss: 0.0555 - val_loss: 0.0630\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 0s 65us/step - loss: 0.0551 - val_loss: 0.0626\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.0547 - val_loss: 0.0622\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 0s 44us/step - loss: 0.0544 - val_loss: 0.0618\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 0s 66us/step - loss: 0.0540 - val_loss: 0.0614\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 0s 48us/step - loss: 0.0537 - val_loss: 0.0611\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 0s 58us/step - loss: 0.0533 - val_loss: 0.0607\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 0s 62us/step - loss: 0.0530 - val_loss: 0.0604\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 0s 66us/step - loss: 0.0527 - val_loss: 0.0600\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 0s 46us/step - loss: 0.0524 - val_loss: 0.0597\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 0s 62us/step - loss: 0.0521 - val_loss: 0.0593\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 0s 69us/step - loss: 0.0517 - val_loss: 0.0590\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 0s 69us/step - loss: 0.0515 - val_loss: 0.0587\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 0s 81us/step - loss: 0.0512 - val_loss: 0.0584\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 0s 100us/step - loss: 0.0509 - val_loss: 0.0581\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0506 - val_loss: 0.0578\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.0503 - val_loss: 0.0575\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 0s 54us/step - loss: 0.0501 - val_loss: 0.0572\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 0s 37us/step - loss: 0.0498 - val_loss: 0.0569\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 0s 56us/step - loss: 0.0495 - val_loss: 0.0566\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - 0s 50us/step - loss: 0.0493 - val_loss: 0.0563\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 0s 45us/step - loss: 0.0490 - val_loss: 0.0561\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 0s 50us/step - loss: 0.0488 - val_loss: 0.0558\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - 0s 64us/step - loss: 0.0486 - val_loss: 0.0556\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 0s 54us/step - loss: 0.0483 - val_loss: 0.0553\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 0s 86us/step - loss: 0.0481 - val_loss: 0.0551\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 0s 54us/step - loss: 0.0479 - val_loss: 0.0548\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - 0s 54us/step - loss: 0.0477 - val_loss: 0.0546\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 0s 48us/step - loss: 0.0474 - val_loss: 0.0543\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 0s 62us/step - loss: 0.0472 - val_loss: 0.0541\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.0470 - val_loss: 0.0539\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 0s 57us/step - loss: 0.0468 - val_loss: 0.0537\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 0s 53us/step - loss: 0.0466 - val_loss: 0.0534\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - 0s 126us/step - loss: 0.0464 - val_loss: 0.0532\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0462 - val_loss: 0.0530\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - 0s 57us/step - loss: 0.0461 - val_loss: 0.0528\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - 0s 45us/step - loss: 0.0459 - val_loss: 0.0526\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - 0s 62us/step - loss: 0.0457 - val_loss: 0.0524\n",
            "Epoch 199/500\n",
            "100/100 [==============================] - 0s 50us/step - loss: 0.0455 - val_loss: 0.0522\n",
            "Epoch 200/500\n",
            "100/100 [==============================] - 0s 49us/step - loss: 0.0454 - val_loss: 0.0520\n",
            "Epoch 201/500\n",
            "100/100 [==============================] - 0s 63us/step - loss: 0.0452 - val_loss: 0.0518\n",
            "Epoch 202/500\n",
            "100/100 [==============================] - 0s 48us/step - loss: 0.0450 - val_loss: 0.0516\n",
            "Epoch 203/500\n",
            "100/100 [==============================] - 0s 71us/step - loss: 0.0449 - val_loss: 0.0515\n",
            "Epoch 204/500\n",
            "100/100 [==============================] - 0s 53us/step - loss: 0.0447 - val_loss: 0.0513\n",
            "Epoch 205/500\n",
            "100/100 [==============================] - 0s 57us/step - loss: 0.0445 - val_loss: 0.0511\n",
            "Epoch 206/500\n",
            "100/100 [==============================] - 0s 51us/step - loss: 0.0444 - val_loss: 0.0509\n",
            "Epoch 207/500\n",
            "100/100 [==============================] - 0s 50us/step - loss: 0.0442 - val_loss: 0.0508\n",
            "Epoch 208/500\n",
            "100/100 [==============================] - 0s 72us/step - loss: 0.0441 - val_loss: 0.0506\n",
            "Epoch 209/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.0440 - val_loss: 0.0504\n",
            "Epoch 210/500\n",
            "100/100 [==============================] - 0s 97us/step - loss: 0.0438 - val_loss: 0.0503\n",
            "Epoch 211/500\n",
            "100/100 [==============================] - 0s 69us/step - loss: 0.0437 - val_loss: 0.0501\n",
            "Epoch 212/500\n",
            "100/100 [==============================] - 0s 79us/step - loss: 0.0435 - val_loss: 0.0500\n",
            "Epoch 213/500\n",
            "100/100 [==============================] - 0s 69us/step - loss: 0.0434 - val_loss: 0.0498\n",
            "Epoch 214/500\n",
            "100/100 [==============================] - 0s 80us/step - loss: 0.0433 - val_loss: 0.0497\n",
            "Epoch 215/500\n",
            "100/100 [==============================] - 0s 63us/step - loss: 0.0431 - val_loss: 0.0495\n",
            "Epoch 216/500\n",
            "100/100 [==============================] - 0s 41us/step - loss: 0.0430 - val_loss: 0.0494\n",
            "Epoch 217/500\n",
            "100/100 [==============================] - 0s 76us/step - loss: 0.0429 - val_loss: 0.0492\n",
            "Epoch 218/500\n",
            "100/100 [==============================] - 0s 40us/step - loss: 0.0428 - val_loss: 0.0491\n",
            "Epoch 219/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0426 - val_loss: 0.0490\n",
            "Epoch 220/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.0425 - val_loss: 0.0488\n",
            "Epoch 221/500\n",
            "100/100 [==============================] - 0s 62us/step - loss: 0.0424 - val_loss: 0.0487\n",
            "Epoch 222/500\n",
            "100/100 [==============================] - 0s 54us/step - loss: 0.0423 - val_loss: 0.0486\n",
            "Epoch 223/500\n",
            "100/100 [==============================] - 0s 50us/step - loss: 0.0422 - val_loss: 0.0484\n",
            "Epoch 224/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0421 - val_loss: 0.0483\n",
            "Epoch 225/500\n",
            "100/100 [==============================] - 0s 77us/step - loss: 0.0420 - val_loss: 0.0482\n",
            "Epoch 226/500\n",
            "100/100 [==============================] - 0s 60us/step - loss: 0.0419 - val_loss: 0.0480\n",
            "Epoch 227/500\n",
            "100/100 [==============================] - 0s 71us/step - loss: 0.0418 - val_loss: 0.0479\n",
            "Epoch 228/500\n",
            "100/100 [==============================] - 0s 65us/step - loss: 0.0417 - val_loss: 0.0478\n",
            "Epoch 229/500\n",
            "100/100 [==============================] - 0s 66us/step - loss: 0.0416 - val_loss: 0.0477\n",
            "Epoch 230/500\n",
            "100/100 [==============================] - 0s 52us/step - loss: 0.0415 - val_loss: 0.0476\n",
            "Epoch 231/500\n",
            "100/100 [==============================] - 0s 49us/step - loss: 0.0414 - val_loss: 0.0475\n",
            "Epoch 232/500\n",
            "100/100 [==============================] - 0s 46us/step - loss: 0.0413 - val_loss: 0.0474\n",
            "Epoch 233/500\n",
            "100/100 [==============================] - 0s 65us/step - loss: 0.0412 - val_loss: 0.0472\n",
            "Epoch 234/500\n",
            "100/100 [==============================] - 0s 62us/step - loss: 0.0411 - val_loss: 0.0471\n",
            "Epoch 235/500\n",
            "100/100 [==============================] - 0s 63us/step - loss: 0.0410 - val_loss: 0.0470\n",
            "Epoch 236/500\n",
            "100/100 [==============================] - 0s 56us/step - loss: 0.0409 - val_loss: 0.0469\n",
            "Epoch 237/500\n",
            "100/100 [==============================] - 0s 46us/step - loss: 0.0408 - val_loss: 0.0468\n",
            "Epoch 238/500\n",
            "100/100 [==============================] - 0s 36us/step - loss: 0.0407 - val_loss: 0.0467\n",
            "Epoch 239/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0407 - val_loss: 0.0466\n",
            "Epoch 240/500\n",
            "100/100 [==============================] - 0s 35us/step - loss: 0.0406 - val_loss: 0.0465\n",
            "Epoch 241/500\n",
            "100/100 [==============================] - 0s 54us/step - loss: 0.0405 - val_loss: 0.0464\n",
            "Epoch 242/500\n",
            "100/100 [==============================] - 0s 98us/step - loss: 0.0404 - val_loss: 0.0463\n",
            "Epoch 243/500\n",
            "100/100 [==============================] - 0s 35us/step - loss: 0.0403 - val_loss: 0.0462\n",
            "Epoch 244/500\n",
            "100/100 [==============================] - 0s 68us/step - loss: 0.0403 - val_loss: 0.0461\n",
            "Epoch 245/500\n",
            "100/100 [==============================] - 0s 72us/step - loss: 0.0402 - val_loss: 0.0460\n",
            "Epoch 246/500\n",
            "100/100 [==============================] - 0s 60us/step - loss: 0.0401 - val_loss: 0.0460\n",
            "Epoch 247/500\n",
            "100/100 [==============================] - 0s 44us/step - loss: 0.0400 - val_loss: 0.0459\n",
            "Epoch 248/500\n",
            "100/100 [==============================] - 0s 50us/step - loss: 0.0400 - val_loss: 0.0458\n",
            "Epoch 249/500\n",
            "100/100 [==============================] - 0s 47us/step - loss: 0.0399 - val_loss: 0.0457\n",
            "Epoch 250/500\n",
            "100/100 [==============================] - 0s 50us/step - loss: 0.0398 - val_loss: 0.0456\n",
            "Epoch 251/500\n",
            "100/100 [==============================] - 0s 52us/step - loss: 0.0398 - val_loss: 0.0455\n",
            "Epoch 252/500\n",
            "100/100 [==============================] - 0s 62us/step - loss: 0.0397 - val_loss: 0.0454\n",
            "Epoch 253/500\n",
            "100/100 [==============================] - 0s 54us/step - loss: 0.0396 - val_loss: 0.0454\n",
            "Epoch 254/500\n",
            "100/100 [==============================] - 0s 35us/step - loss: 0.0396 - val_loss: 0.0453\n",
            "Epoch 255/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0395 - val_loss: 0.0452\n",
            "Epoch 256/500\n",
            "100/100 [==============================] - 0s 37us/step - loss: 0.0394 - val_loss: 0.0451\n",
            "Epoch 257/500\n",
            "100/100 [==============================] - 0s 56us/step - loss: 0.0394 - val_loss: 0.0451\n",
            "Epoch 258/500\n",
            "100/100 [==============================] - 0s 56us/step - loss: 0.0393 - val_loss: 0.0450\n",
            "Epoch 259/500\n",
            "100/100 [==============================] - 0s 44us/step - loss: 0.0392 - val_loss: 0.0449\n",
            "Epoch 260/500\n",
            "100/100 [==============================] - 0s 62us/step - loss: 0.0392 - val_loss: 0.0448\n",
            "Epoch 261/500\n",
            "100/100 [==============================] - 0s 43us/step - loss: 0.0391 - val_loss: 0.0448\n",
            "Epoch 262/500\n",
            "100/100 [==============================] - 0s 62us/step - loss: 0.0391 - val_loss: 0.0447\n",
            "Epoch 263/500\n",
            "100/100 [==============================] - 0s 44us/step - loss: 0.0390 - val_loss: 0.0446\n",
            "Epoch 264/500\n",
            "100/100 [==============================] - 0s 61us/step - loss: 0.0390 - val_loss: 0.0445\n",
            "Epoch 265/500\n",
            "100/100 [==============================] - 0s 51us/step - loss: 0.0389 - val_loss: 0.0445\n",
            "Epoch 266/500\n",
            "100/100 [==============================] - 0s 72us/step - loss: 0.0388 - val_loss: 0.0444\n",
            "Epoch 267/500\n",
            "100/100 [==============================] - 0s 45us/step - loss: 0.0388 - val_loss: 0.0443\n",
            "Epoch 268/500\n",
            "100/100 [==============================] - 0s 39us/step - loss: 0.0387 - val_loss: 0.0443\n",
            "Epoch 269/500\n",
            "100/100 [==============================] - 0s 38us/step - loss: 0.0387 - val_loss: 0.0442\n",
            "Epoch 270/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.0386 - val_loss: 0.0442\n",
            "Epoch 271/500\n",
            "100/100 [==============================] - 0s 52us/step - loss: 0.0386 - val_loss: 0.0441\n",
            "Epoch 272/500\n",
            "100/100 [==============================] - 0s 57us/step - loss: 0.0385 - val_loss: 0.0440\n",
            "Epoch 273/500\n",
            "100/100 [==============================] - 0s 58us/step - loss: 0.0385 - val_loss: 0.0440\n",
            "Epoch 274/500\n",
            "100/100 [==============================] - 0s 61us/step - loss: 0.0384 - val_loss: 0.0439\n",
            "Epoch 275/500\n",
            "100/100 [==============================] - 0s 111us/step - loss: 0.0384 - val_loss: 0.0438\n",
            "Epoch 276/500\n",
            "100/100 [==============================] - 0s 56us/step - loss: 0.0383 - val_loss: 0.0438\n",
            "Epoch 277/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0383 - val_loss: 0.0437\n",
            "Epoch 278/500\n",
            "100/100 [==============================] - 0s 40us/step - loss: 0.0382 - val_loss: 0.0437\n",
            "Epoch 279/500\n",
            "100/100 [==============================] - 0s 64us/step - loss: 0.0382 - val_loss: 0.0436\n",
            "Epoch 280/500\n",
            "100/100 [==============================] - 0s 58us/step - loss: 0.0382 - val_loss: 0.0436\n",
            "Epoch 281/500\n",
            "100/100 [==============================] - 0s 52us/step - loss: 0.0381 - val_loss: 0.0435\n",
            "Epoch 282/500\n",
            "100/100 [==============================] - 0s 66us/step - loss: 0.0381 - val_loss: 0.0435\n",
            "Epoch 283/500\n",
            "100/100 [==============================] - 0s 77us/step - loss: 0.0380 - val_loss: 0.0434\n",
            "Epoch 284/500\n",
            "100/100 [==============================] - 0s 73us/step - loss: 0.0380 - val_loss: 0.0433\n",
            "Epoch 285/500\n",
            "100/100 [==============================] - 0s 47us/step - loss: 0.0379 - val_loss: 0.0433\n",
            "Epoch 286/500\n",
            "100/100 [==============================] - 0s 89us/step - loss: 0.0379 - val_loss: 0.0432\n",
            "Epoch 287/500\n",
            "100/100 [==============================] - 0s 105us/step - loss: 0.0379 - val_loss: 0.0432\n",
            "Epoch 288/500\n",
            "100/100 [==============================] - 0s 54us/step - loss: 0.0378 - val_loss: 0.0431\n",
            "Epoch 289/500\n",
            "100/100 [==============================] - 0s 52us/step - loss: 0.0378 - val_loss: 0.0431\n",
            "Epoch 290/500\n",
            "100/100 [==============================] - 0s 54us/step - loss: 0.0377 - val_loss: 0.0430\n",
            "Epoch 291/500\n",
            "100/100 [==============================] - 0s 58us/step - loss: 0.0377 - val_loss: 0.0430\n",
            "Epoch 292/500\n",
            "100/100 [==============================] - 0s 95us/step - loss: 0.0377 - val_loss: 0.0429\n",
            "Epoch 293/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0376 - val_loss: 0.0429\n",
            "Epoch 294/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.0376 - val_loss: 0.0428\n",
            "Epoch 295/500\n",
            "100/100 [==============================] - 0s 46us/step - loss: 0.0376 - val_loss: 0.0428\n",
            "Epoch 296/500\n",
            "100/100 [==============================] - 0s 57us/step - loss: 0.0375 - val_loss: 0.0428\n",
            "Epoch 297/500\n",
            "100/100 [==============================] - 0s 57us/step - loss: 0.0375 - val_loss: 0.0427\n",
            "Epoch 298/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.0375 - val_loss: 0.0427\n",
            "Epoch 299/500\n",
            "100/100 [==============================] - 0s 50us/step - loss: 0.0374 - val_loss: 0.0426\n",
            "Epoch 300/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.0374 - val_loss: 0.0426\n",
            "Epoch 301/500\n",
            "100/100 [==============================] - 0s 62us/step - loss: 0.0374 - val_loss: 0.0425\n",
            "Epoch 302/500\n",
            "100/100 [==============================] - 0s 66us/step - loss: 0.0373 - val_loss: 0.0425\n",
            "Epoch 303/500\n",
            "100/100 [==============================] - 0s 50us/step - loss: 0.0373 - val_loss: 0.0425\n",
            "Epoch 304/500\n",
            "100/100 [==============================] - 0s 51us/step - loss: 0.0373 - val_loss: 0.0424\n",
            "Epoch 305/500\n",
            "100/100 [==============================] - 0s 50us/step - loss: 0.0372 - val_loss: 0.0424\n",
            "Epoch 306/500\n",
            "100/100 [==============================] - 0s 48us/step - loss: 0.0372 - val_loss: 0.0423\n",
            "Epoch 307/500\n",
            "100/100 [==============================] - 0s 52us/step - loss: 0.0372 - val_loss: 0.0423\n",
            "Epoch 308/500\n",
            "100/100 [==============================] - 0s 50us/step - loss: 0.0371 - val_loss: 0.0422\n",
            "Epoch 309/500\n",
            "100/100 [==============================] - 0s 84us/step - loss: 0.0371 - val_loss: 0.0422\n",
            "Epoch 310/500\n",
            "100/100 [==============================] - 0s 37us/step - loss: 0.0371 - val_loss: 0.0422\n",
            "Epoch 311/500\n",
            "100/100 [==============================] - 0s 51us/step - loss: 0.0370 - val_loss: 0.0421\n",
            "Epoch 312/500\n",
            "100/100 [==============================] - 0s 75us/step - loss: 0.0370 - val_loss: 0.0421\n",
            "Epoch 313/500\n",
            "100/100 [==============================] - 0s 56us/step - loss: 0.0370 - val_loss: 0.0421\n",
            "Epoch 314/500\n",
            "100/100 [==============================] - 0s 40us/step - loss: 0.0370 - val_loss: 0.0420\n",
            "Epoch 315/500\n",
            "100/100 [==============================] - 0s 47us/step - loss: 0.0369 - val_loss: 0.0420\n",
            "Epoch 316/500\n",
            "100/100 [==============================] - 0s 49us/step - loss: 0.0369 - val_loss: 0.0419\n",
            "Epoch 317/500\n",
            "100/100 [==============================] - 0s 39us/step - loss: 0.0369 - val_loss: 0.0419\n",
            "Epoch 318/500\n",
            "100/100 [==============================] - 0s 73us/step - loss: 0.0368 - val_loss: 0.0419\n",
            "Epoch 319/500\n",
            "100/100 [==============================] - 0s 43us/step - loss: 0.0368 - val_loss: 0.0418\n",
            "Epoch 320/500\n",
            "100/100 [==============================] - 0s 44us/step - loss: 0.0368 - val_loss: 0.0418\n",
            "Epoch 321/500\n",
            "100/100 [==============================] - 0s 51us/step - loss: 0.0368 - val_loss: 0.0418\n",
            "Epoch 322/500\n",
            "100/100 [==============================] - 0s 66us/step - loss: 0.0367 - val_loss: 0.0417\n",
            "Epoch 323/500\n",
            "100/100 [==============================] - 0s 53us/step - loss: 0.0367 - val_loss: 0.0417\n",
            "Epoch 324/500\n",
            "100/100 [==============================] - 0s 48us/step - loss: 0.0367 - val_loss: 0.0417\n",
            "Epoch 325/500\n",
            "100/100 [==============================] - 0s 86us/step - loss: 0.0367 - val_loss: 0.0416\n",
            "Epoch 326/500\n",
            "100/100 [==============================] - 0s 46us/step - loss: 0.0366 - val_loss: 0.0416\n",
            "Epoch 327/500\n",
            "100/100 [==============================] - 0s 56us/step - loss: 0.0366 - val_loss: 0.0416\n",
            "Epoch 328/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.0366 - val_loss: 0.0415\n",
            "Epoch 329/500\n",
            "100/100 [==============================] - 0s 54us/step - loss: 0.0366 - val_loss: 0.0415\n",
            "Epoch 330/500\n",
            "100/100 [==============================] - 0s 63us/step - loss: 0.0365 - val_loss: 0.0415\n",
            "Epoch 331/500\n",
            "100/100 [==============================] - 0s 71us/step - loss: 0.0365 - val_loss: 0.0414\n",
            "Epoch 332/500\n",
            "100/100 [==============================] - 0s 42us/step - loss: 0.0365 - val_loss: 0.0414\n",
            "Epoch 333/500\n",
            "100/100 [==============================] - 0s 61us/step - loss: 0.0365 - val_loss: 0.0414\n",
            "Epoch 334/500\n",
            "100/100 [==============================] - 0s 60us/step - loss: 0.0364 - val_loss: 0.0414\n",
            "Epoch 335/500\n",
            "100/100 [==============================] - 0s 35us/step - loss: 0.0364 - val_loss: 0.0413\n",
            "Epoch 336/500\n",
            "100/100 [==============================] - 0s 41us/step - loss: 0.0364 - val_loss: 0.0413\n",
            "Epoch 337/500\n",
            "100/100 [==============================] - 0s 51us/step - loss: 0.0364 - val_loss: 0.0413\n",
            "Epoch 338/500\n",
            "100/100 [==============================] - 0s 62us/step - loss: 0.0364 - val_loss: 0.0412\n",
            "Epoch 339/500\n",
            "100/100 [==============================] - 0s 58us/step - loss: 0.0363 - val_loss: 0.0412\n",
            "Epoch 340/500\n",
            "100/100 [==============================] - 0s 56us/step - loss: 0.0363 - val_loss: 0.0412\n",
            "Epoch 341/500\n",
            "100/100 [==============================] - 0s 58us/step - loss: 0.0363 - val_loss: 0.0412\n",
            "Epoch 342/500\n",
            "100/100 [==============================] - 0s 54us/step - loss: 0.0363 - val_loss: 0.0411\n",
            "Epoch 343/500\n",
            "100/100 [==============================] - 0s 53us/step - loss: 0.0363 - val_loss: 0.0411\n",
            "Epoch 344/500\n",
            "100/100 [==============================] - 0s 71us/step - loss: 0.0362 - val_loss: 0.0411\n",
            "Epoch 345/500\n",
            "100/100 [==============================] - 0s 65us/step - loss: 0.0362 - val_loss: 0.0410\n",
            "Epoch 346/500\n",
            "100/100 [==============================] - 0s 97us/step - loss: 0.0362 - val_loss: 0.0410\n",
            "Epoch 347/500\n",
            "100/100 [==============================] - 0s 39us/step - loss: 0.0362 - val_loss: 0.0410\n",
            "Epoch 348/500\n",
            "100/100 [==============================] - 0s 58us/step - loss: 0.0361 - val_loss: 0.0410\n",
            "Epoch 349/500\n",
            "100/100 [==============================] - 0s 60us/step - loss: 0.0361 - val_loss: 0.0409\n",
            "Epoch 350/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0361 - val_loss: 0.0409\n",
            "Epoch 351/500\n",
            "100/100 [==============================] - 0s 58us/step - loss: 0.0361 - val_loss: 0.0409\n",
            "Epoch 352/500\n",
            "100/100 [==============================] - 0s 56us/step - loss: 0.0361 - val_loss: 0.0409\n",
            "Epoch 353/500\n",
            "100/100 [==============================] - 0s 58us/step - loss: 0.0361 - val_loss: 0.0408\n",
            "Epoch 354/500\n",
            "100/100 [==============================] - 0s 67us/step - loss: 0.0360 - val_loss: 0.0408\n",
            "Epoch 355/500\n",
            "100/100 [==============================] - 0s 34us/step - loss: 0.0360 - val_loss: 0.0408\n",
            "Epoch 356/500\n",
            "100/100 [==============================] - 0s 36us/step - loss: 0.0360 - val_loss: 0.0408\n",
            "Epoch 357/500\n",
            "100/100 [==============================] - 0s 52us/step - loss: 0.0360 - val_loss: 0.0407\n",
            "Epoch 358/500\n",
            "100/100 [==============================] - 0s 72us/step - loss: 0.0360 - val_loss: 0.0407\n",
            "Epoch 359/500\n",
            "100/100 [==============================] - 0s 46us/step - loss: 0.0359 - val_loss: 0.0407\n",
            "Epoch 360/500\n",
            "100/100 [==============================] - 0s 44us/step - loss: 0.0359 - val_loss: 0.0407\n",
            "Epoch 361/500\n",
            "100/100 [==============================] - 0s 43us/step - loss: 0.0359 - val_loss: 0.0406\n",
            "Epoch 362/500\n",
            "100/100 [==============================] - 0s 51us/step - loss: 0.0359 - val_loss: 0.0406\n",
            "Epoch 363/500\n",
            "100/100 [==============================] - 0s 49us/step - loss: 0.0359 - val_loss: 0.0406\n",
            "Epoch 364/500\n",
            "100/100 [==============================] - 0s 51us/step - loss: 0.0358 - val_loss: 0.0406\n",
            "Epoch 365/500\n",
            "100/100 [==============================] - 0s 51us/step - loss: 0.0358 - val_loss: 0.0405\n",
            "Epoch 366/500\n",
            "100/100 [==============================] - 0s 50us/step - loss: 0.0358 - val_loss: 0.0405\n",
            "Epoch 367/500\n",
            "100/100 [==============================] - 0s 63us/step - loss: 0.0358 - val_loss: 0.0405\n",
            "Epoch 368/500\n",
            "100/100 [==============================] - 0s 52us/step - loss: 0.0358 - val_loss: 0.0405\n",
            "Epoch 369/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0358 - val_loss: 0.0405\n",
            "Epoch 370/500\n",
            "100/100 [==============================] - 0s 48us/step - loss: 0.0357 - val_loss: 0.0404\n",
            "Epoch 371/500\n",
            "100/100 [==============================] - 0s 41us/step - loss: 0.0357 - val_loss: 0.0404\n",
            "Epoch 372/500\n",
            "100/100 [==============================] - 0s 44us/step - loss: 0.0357 - val_loss: 0.0404\n",
            "Epoch 373/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.0357 - val_loss: 0.0404\n",
            "Epoch 374/500\n",
            "100/100 [==============================] - 0s 64us/step - loss: 0.0357 - val_loss: 0.0404\n",
            "Epoch 375/500\n",
            "100/100 [==============================] - 0s 56us/step - loss: 0.0357 - val_loss: 0.0403\n",
            "Epoch 376/500\n",
            "100/100 [==============================] - 0s 54us/step - loss: 0.0356 - val_loss: 0.0403\n",
            "Epoch 377/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0356 - val_loss: 0.0403\n",
            "Epoch 378/500\n",
            "100/100 [==============================] - 0s 65us/step - loss: 0.0356 - val_loss: 0.0403\n",
            "Epoch 379/500\n",
            "100/100 [==============================] - 0s 57us/step - loss: 0.0356 - val_loss: 0.0402\n",
            "Epoch 380/500\n",
            "100/100 [==============================] - 0s 61us/step - loss: 0.0356 - val_loss: 0.0402\n",
            "Epoch 381/500\n",
            "100/100 [==============================] - 0s 53us/step - loss: 0.0356 - val_loss: 0.0402\n",
            "Epoch 382/500\n",
            "100/100 [==============================] - 0s 54us/step - loss: 0.0356 - val_loss: 0.0402\n",
            "Epoch 383/500\n",
            "100/100 [==============================] - 0s 60us/step - loss: 0.0355 - val_loss: 0.0402\n",
            "Epoch 384/500\n",
            "100/100 [==============================] - 0s 60us/step - loss: 0.0355 - val_loss: 0.0402\n",
            "Epoch 385/500\n",
            "100/100 [==============================] - 0s 51us/step - loss: 0.0355 - val_loss: 0.0401\n",
            "Epoch 386/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0355 - val_loss: 0.0401\n",
            "Epoch 387/500\n",
            "100/100 [==============================] - 0s 61us/step - loss: 0.0355 - val_loss: 0.0401\n",
            "Epoch 388/500\n",
            "100/100 [==============================] - 0s 104us/step - loss: 0.0355 - val_loss: 0.0401\n",
            "Epoch 389/500\n",
            "100/100 [==============================] - 0s 49us/step - loss: 0.0355 - val_loss: 0.0401\n",
            "Epoch 390/500\n",
            "100/100 [==============================] - 0s 35us/step - loss: 0.0354 - val_loss: 0.0400\n",
            "Epoch 391/500\n",
            "100/100 [==============================] - 0s 47us/step - loss: 0.0354 - val_loss: 0.0400\n",
            "Epoch 392/500\n",
            "100/100 [==============================] - 0s 46us/step - loss: 0.0354 - val_loss: 0.0400\n",
            "Epoch 393/500\n",
            "100/100 [==============================] - 0s 44us/step - loss: 0.0354 - val_loss: 0.0400\n",
            "Epoch 394/500\n",
            "100/100 [==============================] - 0s 49us/step - loss: 0.0354 - val_loss: 0.0400\n",
            "Epoch 395/500\n",
            "100/100 [==============================] - 0s 62us/step - loss: 0.0354 - val_loss: 0.0399\n",
            "Epoch 396/500\n",
            "100/100 [==============================] - 0s 65us/step - loss: 0.0354 - val_loss: 0.0399\n",
            "Epoch 397/500\n",
            "100/100 [==============================] - 0s 63us/step - loss: 0.0353 - val_loss: 0.0399\n",
            "Epoch 398/500\n",
            "100/100 [==============================] - 0s 61us/step - loss: 0.0353 - val_loss: 0.0399\n",
            "Epoch 399/500\n",
            "100/100 [==============================] - 0s 52us/step - loss: 0.0353 - val_loss: 0.0399\n",
            "Epoch 400/500\n",
            "100/100 [==============================] - 0s 46us/step - loss: 0.0353 - val_loss: 0.0399\n",
            "Epoch 401/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.0353 - val_loss: 0.0398\n",
            "Epoch 402/500\n",
            "100/100 [==============================] - 0s 52us/step - loss: 0.0353 - val_loss: 0.0398\n",
            "Epoch 403/500\n",
            "100/100 [==============================] - 0s 93us/step - loss: 0.0353 - val_loss: 0.0398\n",
            "Epoch 404/500\n",
            "100/100 [==============================] - 0s 93us/step - loss: 0.0352 - val_loss: 0.0398\n",
            "Epoch 405/500\n",
            "100/100 [==============================] - 0s 51us/step - loss: 0.0352 - val_loss: 0.0398\n",
            "Epoch 406/500\n",
            "100/100 [==============================] - 0s 48us/step - loss: 0.0352 - val_loss: 0.0398\n",
            "Epoch 407/500\n",
            "100/100 [==============================] - 0s 61us/step - loss: 0.0352 - val_loss: 0.0397\n",
            "Epoch 408/500\n",
            "100/100 [==============================] - 0s 62us/step - loss: 0.0352 - val_loss: 0.0397\n",
            "Epoch 409/500\n",
            "100/100 [==============================] - 0s 37us/step - loss: 0.0352 - val_loss: 0.0397\n",
            "Epoch 410/500\n",
            "100/100 [==============================] - 0s 45us/step - loss: 0.0352 - val_loss: 0.0397\n",
            "Epoch 411/500\n",
            "100/100 [==============================] - 0s 53us/step - loss: 0.0351 - val_loss: 0.0397\n",
            "Epoch 412/500\n",
            "100/100 [==============================] - 0s 40us/step - loss: 0.0351 - val_loss: 0.0397\n",
            "Epoch 413/500\n",
            "100/100 [==============================] - 0s 41us/step - loss: 0.0351 - val_loss: 0.0396\n",
            "Epoch 414/500\n",
            "100/100 [==============================] - 0s 52us/step - loss: 0.0351 - val_loss: 0.0396\n",
            "Epoch 415/500\n",
            "100/100 [==============================] - 0s 54us/step - loss: 0.0351 - val_loss: 0.0396\n",
            "Epoch 416/500\n",
            "100/100 [==============================] - 0s 65us/step - loss: 0.0351 - val_loss: 0.0396\n",
            "Epoch 417/500\n",
            "100/100 [==============================] - 0s 60us/step - loss: 0.0351 - val_loss: 0.0396\n",
            "Epoch 418/500\n",
            "100/100 [==============================] - 0s 63us/step - loss: 0.0351 - val_loss: 0.0396\n",
            "Epoch 419/500\n",
            "100/100 [==============================] - 0s 73us/step - loss: 0.0350 - val_loss: 0.0395\n",
            "Epoch 420/500\n",
            "100/100 [==============================] - 0s 38us/step - loss: 0.0350 - val_loss: 0.0395\n",
            "Epoch 421/500\n",
            "100/100 [==============================] - 0s 57us/step - loss: 0.0350 - val_loss: 0.0395\n",
            "Epoch 422/500\n",
            "100/100 [==============================] - 0s 57us/step - loss: 0.0350 - val_loss: 0.0395\n",
            "Epoch 423/500\n",
            "100/100 [==============================] - 0s 62us/step - loss: 0.0350 - val_loss: 0.0395\n",
            "Epoch 424/500\n",
            "100/100 [==============================] - 0s 53us/step - loss: 0.0350 - val_loss: 0.0395\n",
            "Epoch 425/500\n",
            "100/100 [==============================] - 0s 47us/step - loss: 0.0350 - val_loss: 0.0395\n",
            "Epoch 426/500\n",
            "100/100 [==============================] - 0s 45us/step - loss: 0.0350 - val_loss: 0.0394\n",
            "Epoch 427/500\n",
            "100/100 [==============================] - 0s 61us/step - loss: 0.0350 - val_loss: 0.0394\n",
            "Epoch 428/500\n",
            "100/100 [==============================] - 0s 49us/step - loss: 0.0349 - val_loss: 0.0394\n",
            "Epoch 429/500\n",
            "100/100 [==============================] - 0s 41us/step - loss: 0.0349 - val_loss: 0.0394\n",
            "Epoch 430/500\n",
            "100/100 [==============================] - 0s 52us/step - loss: 0.0349 - val_loss: 0.0394\n",
            "Epoch 431/500\n",
            "100/100 [==============================] - 0s 51us/step - loss: 0.0349 - val_loss: 0.0394\n",
            "Epoch 432/500\n",
            "100/100 [==============================] - 0s 39us/step - loss: 0.0349 - val_loss: 0.0394\n",
            "Epoch 433/500\n",
            "100/100 [==============================] - 0s 62us/step - loss: 0.0349 - val_loss: 0.0393\n",
            "Epoch 434/500\n",
            "100/100 [==============================] - 0s 64us/step - loss: 0.0349 - val_loss: 0.0393\n",
            "Epoch 435/500\n",
            "100/100 [==============================] - 0s 44us/step - loss: 0.0349 - val_loss: 0.0393\n",
            "Epoch 436/500\n",
            "100/100 [==============================] - 0s 45us/step - loss: 0.0348 - val_loss: 0.0393\n",
            "Epoch 437/500\n",
            "100/100 [==============================] - 0s 33us/step - loss: 0.0348 - val_loss: 0.0393\n",
            "Epoch 438/500\n",
            "100/100 [==============================] - 0s 46us/step - loss: 0.0348 - val_loss: 0.0393\n",
            "Epoch 439/500\n",
            "100/100 [==============================] - 0s 63us/step - loss: 0.0348 - val_loss: 0.0393\n",
            "Epoch 440/500\n",
            "100/100 [==============================] - 0s 68us/step - loss: 0.0348 - val_loss: 0.0392\n",
            "Epoch 441/500\n",
            "100/100 [==============================] - 0s 61us/step - loss: 0.0348 - val_loss: 0.0392\n",
            "Epoch 442/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0348 - val_loss: 0.0392\n",
            "Epoch 443/500\n",
            "100/100 [==============================] - 0s 45us/step - loss: 0.0348 - val_loss: 0.0392\n",
            "Epoch 444/500\n",
            "100/100 [==============================] - 0s 37us/step - loss: 0.0348 - val_loss: 0.0392\n",
            "Epoch 445/500\n",
            "100/100 [==============================] - 0s 46us/step - loss: 0.0347 - val_loss: 0.0392\n",
            "Epoch 446/500\n",
            "100/100 [==============================] - 0s 64us/step - loss: 0.0347 - val_loss: 0.0392\n",
            "Epoch 447/500\n",
            "100/100 [==============================] - 0s 51us/step - loss: 0.0347 - val_loss: 0.0391\n",
            "Epoch 448/500\n",
            "100/100 [==============================] - 0s 56us/step - loss: 0.0347 - val_loss: 0.0391\n",
            "Epoch 449/500\n",
            "100/100 [==============================] - 0s 56us/step - loss: 0.0347 - val_loss: 0.0391\n",
            "Epoch 450/500\n",
            "100/100 [==============================] - 0s 46us/step - loss: 0.0347 - val_loss: 0.0391\n",
            "Epoch 451/500\n",
            "100/100 [==============================] - 0s 88us/step - loss: 0.0347 - val_loss: 0.0391\n",
            "Epoch 452/500\n",
            "100/100 [==============================] - 0s 47us/step - loss: 0.0347 - val_loss: 0.0391\n",
            "Epoch 453/500\n",
            "100/100 [==============================] - 0s 66us/step - loss: 0.0347 - val_loss: 0.0391\n",
            "Epoch 454/500\n",
            "100/100 [==============================] - 0s 63us/step - loss: 0.0346 - val_loss: 0.0391\n",
            "Epoch 455/500\n",
            "100/100 [==============================] - 0s 64us/step - loss: 0.0346 - val_loss: 0.0390\n",
            "Epoch 456/500\n",
            "100/100 [==============================] - 0s 57us/step - loss: 0.0346 - val_loss: 0.0390\n",
            "Epoch 457/500\n",
            "100/100 [==============================] - 0s 57us/step - loss: 0.0346 - val_loss: 0.0390\n",
            "Epoch 458/500\n",
            "100/100 [==============================] - 0s 66us/step - loss: 0.0346 - val_loss: 0.0390\n",
            "Epoch 459/500\n",
            "100/100 [==============================] - 0s 54us/step - loss: 0.0346 - val_loss: 0.0390\n",
            "Epoch 460/500\n",
            "100/100 [==============================] - 0s 61us/step - loss: 0.0346 - val_loss: 0.0390\n",
            "Epoch 461/500\n",
            "100/100 [==============================] - 0s 49us/step - loss: 0.0346 - val_loss: 0.0390\n",
            "Epoch 462/500\n",
            "100/100 [==============================] - 0s 70us/step - loss: 0.0346 - val_loss: 0.0390\n",
            "Epoch 463/500\n",
            "100/100 [==============================] - 0s 44us/step - loss: 0.0345 - val_loss: 0.0389\n",
            "Epoch 464/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.0345 - val_loss: 0.0389\n",
            "Epoch 465/500\n",
            "100/100 [==============================] - 0s 67us/step - loss: 0.0345 - val_loss: 0.0389\n",
            "Epoch 466/500\n",
            "100/100 [==============================] - 0s 42us/step - loss: 0.0345 - val_loss: 0.0389\n",
            "Epoch 467/500\n",
            "100/100 [==============================] - 0s 58us/step - loss: 0.0345 - val_loss: 0.0389\n",
            "Epoch 468/500\n",
            "100/100 [==============================] - 0s 53us/step - loss: 0.0345 - val_loss: 0.0389\n",
            "Epoch 469/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0345 - val_loss: 0.0389\n",
            "Epoch 470/500\n",
            "100/100 [==============================] - 0s 50us/step - loss: 0.0345 - val_loss: 0.0389\n",
            "Epoch 471/500\n",
            "100/100 [==============================] - 0s 54us/step - loss: 0.0345 - val_loss: 0.0388\n",
            "Epoch 472/500\n",
            "100/100 [==============================] - 0s 53us/step - loss: 0.0345 - val_loss: 0.0388\n",
            "Epoch 473/500\n",
            "100/100 [==============================] - 0s 45us/step - loss: 0.0344 - val_loss: 0.0388\n",
            "Epoch 474/500\n",
            "100/100 [==============================] - 0s 68us/step - loss: 0.0344 - val_loss: 0.0388\n",
            "Epoch 475/500\n",
            "100/100 [==============================] - 0s 38us/step - loss: 0.0344 - val_loss: 0.0388\n",
            "Epoch 476/500\n",
            "100/100 [==============================] - 0s 46us/step - loss: 0.0344 - val_loss: 0.0388\n",
            "Epoch 477/500\n",
            "100/100 [==============================] - 0s 93us/step - loss: 0.0344 - val_loss: 0.0388\n",
            "Epoch 478/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0344 - val_loss: 0.0388\n",
            "Epoch 479/500\n",
            "100/100 [==============================] - 0s 60us/step - loss: 0.0344 - val_loss: 0.0388\n",
            "Epoch 480/500\n",
            "100/100 [==============================] - 0s 52us/step - loss: 0.0344 - val_loss: 0.0387\n",
            "Epoch 481/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.0344 - val_loss: 0.0387\n",
            "Epoch 482/500\n",
            "100/100 [==============================] - 0s 110us/step - loss: 0.0344 - val_loss: 0.0387\n",
            "Epoch 483/500\n",
            "100/100 [==============================] - 0s 78us/step - loss: 0.0343 - val_loss: 0.0387\n",
            "Epoch 484/500\n",
            "100/100 [==============================] - 0s 74us/step - loss: 0.0343 - val_loss: 0.0387\n",
            "Epoch 485/500\n",
            "100/100 [==============================] - 0s 39us/step - loss: 0.0343 - val_loss: 0.0387\n",
            "Epoch 486/500\n",
            "100/100 [==============================] - 0s 54us/step - loss: 0.0343 - val_loss: 0.0387\n",
            "Epoch 487/500\n",
            "100/100 [==============================] - 0s 60us/step - loss: 0.0343 - val_loss: 0.0387\n",
            "Epoch 488/500\n",
            "100/100 [==============================] - 0s 55us/step - loss: 0.0343 - val_loss: 0.0387\n",
            "Epoch 489/500\n",
            "100/100 [==============================] - 0s 61us/step - loss: 0.0343 - val_loss: 0.0386\n",
            "Epoch 490/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0343 - val_loss: 0.0386\n",
            "Epoch 491/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0343 - val_loss: 0.0386\n",
            "Epoch 492/500\n",
            "100/100 [==============================] - 0s 56us/step - loss: 0.0343 - val_loss: 0.0386\n",
            "Epoch 493/500\n",
            "100/100 [==============================] - 0s 60us/step - loss: 0.0343 - val_loss: 0.0386\n",
            "Epoch 494/500\n",
            "100/100 [==============================] - 0s 64us/step - loss: 0.0342 - val_loss: 0.0386\n",
            "Epoch 495/500\n",
            "100/100 [==============================] - 0s 63us/step - loss: 0.0342 - val_loss: 0.0386\n",
            "Epoch 496/500\n",
            "100/100 [==============================] - 0s 59us/step - loss: 0.0342 - val_loss: 0.0386\n",
            "Epoch 497/500\n",
            "100/100 [==============================] - 0s 51us/step - loss: 0.0342 - val_loss: 0.0386\n",
            "Epoch 498/500\n",
            "100/100 [==============================] - 0s 38us/step - loss: 0.0342 - val_loss: 0.0385\n",
            "Epoch 499/500\n",
            "100/100 [==============================] - 0s 41us/step - loss: 0.0342 - val_loss: 0.0385\n",
            "Epoch 500/500\n",
            "100/100 [==============================] - 0s 67us/step - loss: 0.0342 - val_loss: 0.0385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f51cc6e81d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E7Yn2idlr15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "1c1a06be-7362-4f0d-a19d-8f29b2bf0371"
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 10        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 12        \n",
            "=================================================================\n",
            "Total params: 22\n",
            "Trainable params: 22\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4jUYisTlC-h"
      },
      "source": [
        "# encode and decode some data points\n",
        "# note that we take them from the *test* set\n",
        "encoded_datapoints = encoder.predict(X_test)\n",
        "decoded_datapoints = decoder.predict(encoded_datapoints)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59FiH-lMlDBt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "e36ecd1e-c80f-439c-cdcf-a4a7c07cfb11"
      },
      "source": [
        "print('Original Datapoints :')\n",
        "print(X_test[0:10])\n",
        "print('Reconstructed Datapoints :')\n",
        "print(decoded_datapoints[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Datapoints :\n",
            "[[5.8 2.8 5.1 2.4]\n",
            " [6.  2.2 4.  1. ]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.1 2.8 4.  1.3]]\n",
            "Reconstructed Datapoints :\n",
            "[[5.9652066  2.5151644  5.241566   1.8997488 ]\n",
            " [5.954404   2.9196062  4.2452097  1.4240468 ]\n",
            " [5.4847717  3.8038976  1.2433732  0.04961214]\n",
            " [7.1700225  3.0631888  6.142641   2.1692839 ]\n",
            " [5.0028567  3.3499446  1.4496872  0.21320996]\n",
            " [6.3739157  2.6217728  5.7386804  2.082865  ]\n",
            " [5.0456753  3.4191115  1.3617473  0.16533855]\n",
            " [6.6682734  3.2426775  4.7830706  1.5856472 ]\n",
            " [6.7404456  3.2208483  4.9690027  1.6649864 ]\n",
            " [6.1095495  3.066553   4.1768513  1.3704504 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OykNu2aRjed2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "d73ff16f-1bd7-4ec3-bc75-5b8885c37b51"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "encoded_dataset = encoder.predict(X)\n",
        "print(X[0:10])\n",
        "print(encoded_dataset[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]]\n",
            "[[-0.8337648   4.8348703 ]\n",
            " [-0.56587666  4.73588   ]\n",
            " [-0.7502444   4.477637  ]\n",
            " [-0.5754727   4.4156456 ]\n",
            " [-0.8948461   4.7106338 ]\n",
            " [-0.73940325  5.175384  ]\n",
            " [-0.7475655   4.385803  ]\n",
            " [-0.7211981   4.763111  ]\n",
            " [-0.53695434  4.2428226 ]\n",
            " [-0.6166701   4.680303  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoARUYsno2oi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "dbc1deaa-74a6-4748-b6d0-1e70d064be7f"
      },
      "source": [
        "plt.scatter(encoded_dataset[:,0], encoded_dataset[:,1], c=y)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd5hU1fnA8e+502c7u/S2FOkoIFgQooCKKPaoqJhoVIzGEmM0tl8ssSXRRGOLPRp7Q7FQjAVFEaRL713YZXuZduee3x+zrMzOzO7sssvuwvt5Hh7cO3fufQfZdw/vPec9SmuNEEKIlsto7gCEEELUThK1EEK0cJKohRCihZNELYQQLZwkaiGEaOHsTXHRnJwcnZub2xSXFkKIg9LChQv3aK3bxnutSRJ1bm4uCxYsaIpLCyHEQUkptSXRa1L6EEKIFk4StRBCtHCSqIUQooWTRC2EEC2cJGohhNhPWmt0aDU6uBCtA41+/SaZ9SGEEIcKbW5GF10JVh5gAzQ6/V4Mz+mNdg8ZUQshRANpbaELfw3hraB9oMtBV0DJHejQmka7jyRqIYRoqNAC0KVAzXbRQXTlG412G0nUQgjRUFZRoheqSiGNQxK1EEI0lGMY6FCcFzwo19hGu40kaiGEaCBlawspl4Py7HPUDfZucKAfJiqlblBKLVdKrVBK/b7R7i6EEEnQOoxV/ixW3mis3UOwCqegzQ3NHRYARtqNqIxHwTkaHEMg7UZUm7dQytVo96hzep5SahBwJXAUEARmKKU+1lqvb7QohBCiFrr0/8D3MeCPHAjORhcsgJxPULaOyV1DawjMQle+DlYFuE9FpVyIihoNN4xyj0G5x+z3dRJJZkTdH5inta7UWpvAbOCcJotICNGqaXMz2v8/tNk4YzkdzgPfNKqTdOQo6AC64qXkr1P2ALrkFgjOBXMZlD+KLpiE1sFGibMpJbPgZTlwv1IqG/ABpwLSw1QIEUXrILr4Ogh8B8oB2kQ7h6Gynt6/Uau5AZQLYhJqCEJLkostvBMq3wT2XTXoh/Bm8H8KnrMaHt8BUOeIWmu9CvgrMAuYASwBwjXPU0pNUUotUEotyM/Pb/RAhRAtmy77ZyRJE4gs/MAPwQXo0gf378K2rnGSNIAN7Icld43gQuKOS7UPHZi9P9EdEEk9TNRav6C1PlJr/QugCFgb55xntdbDtdbD27aNu0mBEOJg5nuH6BErQBB8UyP14QZS9i7gOhao+XDOiUr5Tcz5WlvowHfoipfQ/i/R2gSjDah4V7eD0a7BsR0oSfX6UEq101rnKaW6EalPH9O0YQkhWh3tS/BCELCI9MGo5e3aQlf+FypeBl0GzuNQaTeh7F1RmY+hS++rqlWbYOuByrgHZe8VfQ2rHF04OVLS0GakBGNkQdbroFJAVxK9itCO8l7Q4I98oCTblOm9qhp1CPid1rq4CWMSQrRGzqMg+B0xy6kdQ1Cq9iQNoEvvAt+HVD80DMxAB7+FnE9RtraojPvR6fcAoYQ1b132CJjrifxwIFIyCfuh9M+oNq+gi66qWjFoRH6lP4iy92zY5z2AkkrUWuvRTR2IEKJ1U+l3ogvOBx0gkiidoByo9LvrfG9kZsdUqhMsAFakhlz5Cirtpsg9lJ1a05b/oxrXAAhD8BuwPYnKmQXmusjo39EfpZz1+YjNRtqcCiEahbL3gpzpkXnKoR8jidA7GWXrUPebzbUJZnYEqx4EJsuq5TWNUgocfepxvZZBErUQotEoWztUWgMWL9u6JOiZYYP6lCZcJ1WNqs19DhrgOLLVjJ7jkV4fQohmp+y54BwC1EimyolKuTT566TdArYOoLxVR7ygMlAZDzRSpM1DRtRCiBZBZT6FLr0T/J9FDtg6oNLvR9l7J38NWzbkzAD/THRoReRBofs0lJHSRFEfGJKohRAtgjJSUZmPorU/8rBPZUZqyvW9jnKC53RUI3ava26SqIUQLYpSblDu5g6jRZEatRBCtHCSqIUQooWT0ocQokXQ2ocufwZ8H0QOeM5CpUxBGd7a33gIkEQthGh2WlvogsmRhS97GztVvIAOfA3Z76LUof2P/0P70wshWobgtxDeQHT3vQCEN0JwTnNF1WJIohZCNL/Qj6D9sce1L/LaIU5KH0KIA06HVqL9X6IMF7gngK1jZEqerqxxpify2iFOErUQ4oCySu+HyreAIBoblD0GaXcQWT7u4+c2qQqUE1ynNFusLYWUPoQQB4wOLgLf20R6TltEWtwHoOx+yHwCVMY+ZxvgvVxmfSCJWghxAGnfx/Fr0dig/JEau8SEoeIpdODbAxVeiyWJWghx4CiDBJsXQmgZsXsu+tAV/27ioFo+SdRCiANGuU8nppUpEOkfnaBftLm9CSNqHSRRCyEOGOU8AlIuBdyAo+p3F6Q/AHE75RngHHYgQ2yRZNaHEOKA0YHvITAHsEClgmtMZKdxW1ssXQBljxKZ+QGRWR8eVOq1zRhxyyCJWghxQOjgfHTRFKp3GddBCExHO4eivBdgpFyGtnVEl/87slO4Yxgq7fcoe49mjbslkEQthNgvOvQj2j8LcKI8ExMmVl32MNVJuvqgD8r+gfach1IGyn0Kyi3zpmuSRC2EaDCr9D6ofBsIAga64ll02q0YKRfHnmyuj38RXQ66rMYcarEveZgohEiK1iZ6n53CdXAxVL7Dz4tXTCKLVx5Ch/NiL2DrHP/CyhmpV4uEJFELIWqlw3lYRVehdw9G7z4cq/DXaHMb2j+DmFIGROZKB2bHHk69gcgsj315IOVKlLI1RegHDUnUQoiEtDbRhZMg8A0QjvwKzkMXnk+kJ0ecKXVaQZzEq9wnQvpfwGgH2EClQerVqJSrm/ZDHASkRi2ESCwwG6wiImWNvSywfJFEi5PYUXUQXfpPdMntYOuGSrslkqQBw3sm2nNG1Xtch/yGAMmSPyUhRDVtFWKVv4RV+iDa/wXa3BiZRhejMtKzI/VawAW4QXmIjP0U6N2ABeHN6OI/oP1fVr9TKYVSHknS9SAjaiEEADq4EF10OegwEED73gKjA5E0EYo+WaWgHP1Rnoloz2ng/xKNA8oeAYprXNmPLn8E5R5zQD7HwUh+pAkhInsWFt9Q1bi/qjGSroTwTlAuosd0djCywH0yAMrWGZUyGeU9AyiLfwNzK9qqxCp/HmvP2VgFF6F9n6C1jn++iJLUiFopdSNwBZGnBz8Cl2kdt1ehEKI1MjdE5jLH8IMOAHsfDjrBfSoq/VaUqtlEyQ0qHXRR7GWMzpGHkuZm9ta0dckKCP6Ayri7sT7FQavOEbVSqjNwPTBcaz2IyP+xSU0dmBDiAFI2SDi61fz8MNFAeS9GGW1iL6EUpF4HeGq8YkSuYW4k+sGjD3zvoc1t+xn8wS/Z0ocd8Cil7IAX2Nl0IQkhDjhbD7C1T+LEALryNbRVjK58HV3+ODrwfXUJQ3kvhrTbQOXs8x4LrI1EVi/WoGwQWtgYn+CgVmfpQ2u9Qyn1MLCVSFurWVrrWTXPU0pNAaYAdOvWrbHjFEI0IaUUZD6JLpwMhKrKHWacMyMjY50/BrQF+COzPRxDIetZlHKgUiZhaR+UP5jMncHIbtTPcjBKpvSRBZwJ9AA6ASlKqck1z9NaP6u1Hq61Ht62bdvGj1QI0aSUow+q3deo9Psg9Xoi/aJjzgJzFegKqjei1ZUQXISufO/n0yqfT+aOoFLAeWyjxH8wS6b0cSKwSWudryML/d8HRjZtWEKI5qCUG+U5DSP1t5D6B2LrzZqYqXoA+MD/7s9fWhW13MUeua6tB6rNf4lUVEVtkknUW4FjlFJepZQCxgGrmjYsIURzM1Ivh/T/I/lHWfssJ3celfi09IfBewUYHdDlj6GD8/cnzENCMjXqeUqpd4FFRIpWi4FnmzowIUTzU5jouMvEa/KgPOf//L70W9B75hKzWa37gkhZxNwA+CLlcP8X6NTrMVKvaOToDx5J/ajUWt+lte6ntR6ktb5Ea11zq2AhxMHIaBe3wVKEreqXB1zHgufs6leUvTcq5yNwTQQjB2x9IfMZlHMIhKuSdDU/lD+GtuLMvxaALCEXQtTGNToyq0NXEqlP70uBcwwq9XJwDI3MHNn3VXsuKusfUcesoqsiu7rUpBwQXAhVzZtENFlCLoRISCkHqs3rCRr7mxD6HhyDYpJ0QkYb4qcdDYbs8JKIjKiFaCJaa95ZuZxnFv5Akc/HUZ27cMtxo+mZFbuqb1+mZbGusIA0p5Mu6c2fvJQ9F60yEiwxD0N4O9h71noNrTWEllYlajvRi19U5AeB48hGjPrgIolaiCbyyNw5vLRkET4zsnDks43r+W77Vj658Fd0zYifgGesX8ttn8/CtCxMS9MvJ4enTzuDDqlpBzL0WLZ2YG2PPa7NSIOmWmjtQxdeDuaKfZapK1Deqv9MQ7V5Udqe1kL+ZIRoAmWBAC8sXlidpCFS4fWFQjy9YF7c96zek88fZk2nJBCgIhQiEDZZnrebS6a+2+xd5lTKVcTOqXaCawyqrkRd/gSEfqyqTfvZuxEutp6orBdRbb9C2Xs3TeAHCUnUQjSBjcVFOG2xsyXCWrNoV/xWOS8vXUwoHI45/6fyMpbl7W6SOJOl3GMg7ebISkKVQiRJn4DK+Gvdb/a9T8w0PcKRFY6O/jKSToKUPoRoAp1S0wjWSLoQWRKSmxl/BLqzrJRwnJFzMBzm840bGNyuPUaNh3a7y8v51/y5fLl5I+kuF78ZciTnDajHw716MFImo73nQ3grGG3idtCrSesQWCWJXo1sUtD4oR505EeZEE2gbUoKJ+T2wGWLHgu57HauPjL+qr1fdM/FbY8dO5mWxQuLF3DNJ9Ow9knkRT4fp7/5X95ZuZxd5eWsLSjgntlfcO/XX8Zco7Eo5YzMka4jSetwAVb5k+g9ZxDZFDcO+wBAYZU9hpU3Fiv/RKzyp5FlGrEkUQvRRP45/lQm9umL02bDabPRITWVx0+ZyBEdOsY9/4KBh5Pj9eKIUwrwmSZztm3h6y2bq4/9d9kSygIBTMuKOu+N5cvIr6it18bPdOAbrMLLI7uulD2Otkojx61yrIr/YhXfjFX+DNoqTPpza3MDes94KP931eKWBPX19LvQhRdDxfORB5XhrVD+NLrw8mavybc0UvoQoom47Q7+ftIp/GXMOMqDIbI9nlpLEqlOJx9NuoSbP5vO55s2xqS3ylCImRvWcUJuDwC+376VQJzyistmY2V+Hsen9Kg1Pqv8OSh/gupVguY6tP99dOZzUPSrqsZKPsCNrngW2ryBcvSp83Pr0rurpvLVlmztYG6F8Cai69d+MJdDaAE4R9R5r0OFjKiFaGJuu4McrzepunGG281Z/QaS4qi5zRUYSpHq/Pl498wsbHGuaVoWnVIdWBUvYxVMwiqcgg7MjjpHW2VQ/i+il3IHIZwPhZeCVbDPa37Q5ejSO+qMX2sNwR+oPUkT2aggvKZqxWPNiwQhtKzOex1KZEQtxAEWCof5fNNG1hXuoVdWG07s2TtqhsiY3B7oOInOabNxbv+B1V9fNmQYH65ZRXifKYAOw2BgTia9uAbKNlO9P2FoHtr7G4y0G6qCWB5Zth1TDw6CzosTdWTBilVwOXjPBN+HEN4MjsNRqb+rnl6nlKqjiZMDlAOV8QCYq9DKE7ukXLnASGa3mUOHJGohDqCCykrOfed1Cip9VIaCeB0OMtyzef/8i2iXElmm7XE4eP70s7ny4w+AyBoR0wpz23G/oF/Oz5ty9MnO4alTz+DWz2dSGghgac2xXbry+AkB8G8hKllqH1Q8h/ZejLLlRFYI6gQP+WoT+gZKvvn56/AOdOBLaPM6yjEgcsxzJvimEr360AZGB/CchvJehLJ1Qtt7Qtnfa9xAAS5wn1T/2A5iqimK9sOHD9cLFixo9OsK0dr9fsYnfLp+bdQDQJtSjOvRi39PPDPqXL8Z4pstWwiETY7r2p0sT80FJxGW1uwsKyXV6STT7cEqugYC/4s9UaWgMh5CucejtUYXnAHmehLOyqgP53EYbV4CQFuV6KIrq0btRuQHgmMIqs0zKBX9GXRoNbr4xsgydDTYe6EyH0XZa6+vH4yUUgu11sPjvSYjaiH2w8aiQl5ZuphtpSUc26Ub5w8cTLrLlfD8mRvWRyVpiCxq+WLzRrTWUXVst93BSb3qXrFnKBXdE8TIIfL4yYpzcmQOt1IKsp5DF11d1Rsa6u45XYvQ0ur/VIYXlf0aOrQqcm17b5SjX9y3KUc/VNvp6PAuwEDZ2jU8hoOYJGohGujrLZv57ScfEgqHCWvN3O3beGnJIj66cDJtPN5mi0t5L0T7PiA68SpQaeD4ecCmbB0g+010+XPg/xzCK6nzIWAiceZVK0d/cPRPLmZbh4bd9xAhsz6EaABLa275bAZ+06xeTeg3TfZUVvDkD/F7eQCM79UbuxH9bWdXirG5PRttNaFy9If0v0SaHqnUyO+2rqg2L0ct19Y6gC64ACqeg/AKGpyk8UDKlEaJXcQnI2ohGmBbSQllwdgVdCHL4t2VyzlvwKCoB38bCgtY+NNOxvboyZLdP1FQWUllKITX4SDT7eHmkaN5ftECfti5g15ZWVw8eAid09MbHJ/hPRPtGR9phqRSwN4/5geBrvwQzE1ET9GLx06kjGIBLrD3itS2lQO0BalXoDznNThWUTdJ1EI0gNfpiNuXA6AsGOSct1/nsiOGcdPIUfxx1nRmbFiHAgxlkOKwc/PI0ZQGAvTMasMR7dtz7ttvUBoM4DdNvjIMXl66hFfOPpcjO3ZucIxKudEqBV3xHJib0I5hqNQrULZOkRMCs6g7SUMkQe+teQciyd09EZV6BRidUEbzlXkOFVL6EKIB2npTGNK+I/YE5Qq/afLS0kU89v13zNywDr9p4jNNKkJB8isreX35Uq496hhOPawP/5r/PYW+SvxV86FDloXPDPGnz2buV4w68DW6YBL4p4O5EnxvofecjjY3RU4wskiuI5JFZF/rvXzg/wSwS5I+QCRRC9FAj0+YSK822XHbmQIEzTBvrFgW1ZMaIpXgrSUlbC0pBuDzTRsw44zOt5WWUlAZZ+VeErTW6JI/E3mguHf2Rwh0BbrsEQCU92Ig8QyV2hlVKxDFgSCJWogGapuSwqcX/Yorhg6Pn6wVhK04U+SITKkLmJH5y16HI8EdNK443fTqErYsFu9ciRWOt8LQgmDkYadyDoG0W4BE9wdUevzXlVHnzi6i8UiiFmI/KKW4dMiwuAUEp83GxMP64oqTxFMcTnq1iUxpmzx4SEx7U7thMKpb96jeHslYtSef4158lis/noVpJZjFsc8mskbKZGj7Hah4W4M5wX0mEO9fDE5w/aJesYmGk0QtxH7K8Xq5f+xJuGw2XDY7TiPy++9GHM0tx/2C3MwsvPbIqNRp2PDY7fxz/KnVmwD8ZuiRjOvRE5fNRqrDidfh4LA22fz9pFOSur/WJpZvBuGCKwnnn83VfWeQ6Szk46298Js1kqzygPc3UYcMWwYq83EiW21VjZ73TulLuxGV+VhkZK1SIseNTqg2r6BU/X6IiIaTJeRCNJLd5eXM3LCOkGVxYo9edM/MBCI7tMxYv5Zvt22lU1oa5w0YRKe02Kl3m4qLWJWfR+e0dA5v3yGpedVaB/HtnoRTr8RQVtUxCFkGf144ihM7b2FUh+2AA7dNg/ciVNqtca+twz+hK9+B8HaU61hwn1adjLUOQWgFKGfcqX5i/9W2hFwStRCNYHtpCXd99Tlfb9mM3TA4vU8/7vzFmFqXk8ez6KedvP7jUor9fk7pfRhn9O2f8GFlRTDIuwtu5fzun+KyxdbCfaaNY6b9ijRHkHP7ZvGHUb9CGZkN+nyi6UmvDyGaQMA0mb9zOxWBIHd++RnFVR3swuEwH65Zzao9+UybNDnp0eeLixfyyNw5+E0TDczdvpXXly/jzXMviJus7579BRd2mh83SQNYWnF02518n38Yh7U/SZJ0KyaJWogG+G7bVq7+ZBoaTSgcjtlpJWSF2VRcxA87d9A1PYNXf1zCuoIChnXsxKRBg8l0R3eRK/b7+Pt330Rdx2earNmTz8drV3POPn2oIdLT+qO1qzm7ffzRNhCZIq1c9G/blgm9696Zpb5qNpESTUcStRD1VBrwM+WjD6g0Q7Wep7Vm9uZNvLxsMaZlEQyHmbNtC88vXsCHF0yOWiK+YOcOHDZbTML3mSbT16+LSdSmZZFur2BFYVuGZe/GGWdUrXEwYcBkTu87GEeC8kl9aR1El/0DfG+C9qHtg1AZd6EchzfK9UV8MutDiHqasX5dUucppfh0/VoqQyGCVQnYb5oU+/w89G301lipTlfcnkgKyIxT53YFXmT2xNc4v9cqlNJYOvIQce8vlJe0di9x7oAhCWvctdHmdnTFy+iKV9DhnT8fL74ZKl+v2kJLg/kjuvAStLm53vcQyaszUSul+iqlluzzq1Qp9fsDEZwQLVF5MBjTU7omh2Gje0Ym20tLYl6z0MzeZzdxgBGdOuOJs/DFbbdz8eFDoo7pwPdQ8RQum0maI4TDiGT40qCTtzcNZo/jXlS7uSjnsKQ+j7bK0cHF6PCOSHwV/0HvmYAu+3vkV/54rIo3Ij2jA18Q07daB9EVLyZ1L9EwdSZqrfUarfUQrfUQ4EigEpja5JEJ0UKN6tYdw4itzRpKYQBum50z+/bjlbN+WT1XuiaPPTop2wyDl886l3beFFIdTlKdTlw2GzePHM2QDh2jztWVr8XsM2go8DgU4wf9kfY5k2J2UknEKn8KnXcsuuhydP4pWAXnQ9kjRHYGD1b9HoCyB9DBhZHpeTHCEFqV1P1Ew9S3Rj0O2KC13tIUwQjRGvTJzuHc/gOZunollaFIndrrcHBC9x48PmFi1AO2k3v1ZtaG9YT2GYG7bXYuHBRb0+2X05ZvfzOFBTt3UB4MMrxTZzLc7tgAdGncuJw2By5X7Eh/a0kxoXCYnlltomLT/ulQ/gwQ+HmT29CPxN0ZBiJd82I2wwWwg2NgnOOisdQ3UU8C3oj3glJqCjAFoFu3bvsZlhAt270njGNsj568u3IFYcvirH4DOLlX75hZEPePPYntpaWsLSjAZihMy2J0t1yuGXF03OvaDIOju3SNOa61D132MPjeB+0n7lZb2gTHz2WSDYUFXP3pR2wvLUGhyHC7eOyU0xjRqUvk9IrniW1zmmj/RI0yUtDu8eD/jKjyh3KiUn6T4H2iMSS94EVFlijtBAZqrXfXdq4seBEHO601S3fvYnNxEX2ycxjQtva9/lbk7WZLSQn9cnLomRW7bVVdrMJfQXAxkVJETQbghPQ7MbznA5E53qNeepZCny/qGaXX4eDLX11O25QUrLwxYO1IMgIXKudTsHVAlz8Bla+BrgDHUFT6nT/vQC4arLEWvEwAFtWVpIU42JUG/Fwy9V02FBUCkW25hnXoxPNnnIXbHr8T3cB27RnYrn311wHTZPr6tczZuoVOaWlcMPDwhDu66NAaCC4hNknbwdYNnEeivBeiHIOqX/luyw94jTIKanyLhy2LqatXMuXIEeAaBb73iO41DT+3PjWJzDuxQdqNKHtkpK/SboS0GxP/AYlGV59EfSEJyh5CHEr+/OXnrN6TH1V3XvjTDv4x9ztuH3181LmmZTFn6xZ2l5cxpGMn+mbnUBEM8st33mBbaQmVoRAOw+CFxQv598QzGd0tN/aG5jpQtjjT90yw98bIuL/6iA4tRxffxHHe7cw4xWJVcRtu/P5EtlVEfggEwmF2lkVq3Cr1d2jfu7H3814CnrOh4j+AHzwXY7iSm0EimkZSiVoplQKcBFzVtOEI0bKFLYvp69dGJWmIJMB3Vi6PStTbSkqY9N5blAYCWNpCA2O69+CwNtlsKiokWHWNkGURsiz+MHM6319+FbYam99i7xnZmzCGK2qXb20VogsvAV2BXYHdBoOy9vDGmA854ZOLMLUNr8NRXQPXvqnErUlXvgS+j4GyyNf+mVgpV2Kk3VDPPy3RWJJK1FrrCiC7iWMRosWpDIUwrTDprsjsi7DWCfdKDIajSwi/+3QauyvKsfY5f/qGdUzfEH/BjM8Msb6okGyPl3nbt5HqdDKyazccjgFox4CqGRnBqrNV5CGeZ1L1+7VvGujoxGs3NKmOEMd33Mac3b3pkZnFST17R16seCXBpw6D3lXjD+JFtHMIynV8/LeIJiVLyIWII7+igj9+NoPvt28F4LDsbP5+4in0b9uOIe07sHjXT1GVCAPFL7rnVn+9q7yMdYUFUUm6LpbWTF21gpeXLsZu2FCAw2bwn7N+yaCc59FlD4BvGhACx3BUxt0o2z7jJ3MbMYtRAIehOTxHMyz3GC49Yhj26hF7vAeTCWgfuuJVSdTNRJaQC1GDpTUXvPcmc7dtqS5LrMzP54L33qKgspIHxp1MqtNVvXOL22Yn0+PmztFjqq8RDIfr1bBIATkeL/9dtoRAOExFKEh5KEiR389lH75HGA9Gxv2o9stQ7VdiZL+KsveOvobzSCB2s1mXzcG1I6/k6uFHR69+dIys159LovnboulJohaihrnbt5JfURGz4awZtnh35XL6ZOfwwNgTsRsGhlIErTA9M9vgtP/cU6NregZtPMmtDvTaHbRLSWFA23bVO5HvKxgOM2/HNiDSP0SpBN+27hPB1gnYd/WgOzIrxHlE7PmZ9xJ/c9t4vUHc4J5QxycRTUUStRA1bC8piVuy8IdNNhYXsbGokFv+N5OKUAhLayytWbJrJ7+a+i571yUopXh0/Gl4HY5av8lSHA6eOu0MvrlsCpq4fZkA8IVq79QXuacTlf02pFwKRqfI1L3Ua1FZ/457vmG0gXbfgvtcMNqCrTdkPArpDwFufk4PHrB3R3kvqDMG0TSkRi1EDQP2me+8L6/DwbAOHfnvsiWEarQjNbVmU3ERP+bt5vD2HQAY3qkzX/zqNzz4zdd8tHZV3IXZ95wwrrq2PaF3H77duiWmfWoobHFU5y5Jxa6MVFTaHyHtj9XHtA6h/TPRoTUoe3dwj0epyMNRw0iHzAdjrqMdfdCVb4KVh3KNBc8ZKFW/3WpE45ERtRA1DG7XnmEdO0XtHvbSUPQAACAASURBVG43DDJdbs7o25+1BXtiyiIQKVG8sXxp1LF2Kan8Y/wEJh8+BIdhVO9WroCbjx0V1Wf6tMP6MLh9e7xVdWRDKdx2O3eMPr561kl9aasYvWciuuRPUPEEuvQudP646k55iShHf4yMezCynkZ5z5Mk3cxkz0Qh4giYJk8tmMfbK5YTDIc5uVdvbjp2FNtLS7jg3Tdj5lHvleZ0smjK72LnQgObi4uYu30bGS43Y3v0iLuK0bQsZm1Yx4z168hwu5k0cHDUisb6skruAN9UolcfGuA8GqPNyw2+rmh8srmtEI3k5FdfYn1hYcLXnTYbc39zFVlJPkhsatbuI0GXxXnFhmq/tHqXcdH8akvUUvoQIknFfh9biotrPcdls5FWz53Hm5bsaXgwkEQtRJKcttqfvXvsdq4efvQ+C0paAPepQM0SiwHOY2U03Yq0oL9RQrRsXoeD43N74IiTiN12OzcecxxXHTmiGSJLTKX9Eey5oFIAW+R3ox0q44HmDk3Ug0zPEyIJpYEAfjPEQ2NP5tcfvsem4iIMFCHL4vjuuTw+YWKj7fTdmJSRDtnTIPA1mGvA3h1c42Q03cpIohaiFgWVldw0azpzt2/FUIr2qan8bdx4XA4H20tK6N+2bYM2AjiQlLKBewwwps5zRcskiVoIIlPn/vrt13y3bRtpLieXHjGMS48YyiVT32F9UWH1ruNbS0q4bNpUZk7+NUdULWxJRGtNaSCA227HZZdvNdFw8rdHHPJ2l5dz1luvUR4MYmlNWTDAP7//lnk7trG1tKQ6Se9lWmFeXbaEW0cl7iT3zZbN3PHlZ+wqL8emFGf07cc9J4xLuAOMELWRRC0OeS8tWYTfNKP6e/hMk9lbNuOMU3cOWRYbi4sSXm9lfh5XffJhdYMlE5i2ZjUl/gD/nnhmo8cvDn4y60Mc8hbt2kkwHLvTiSKyQjGeI9olLns8s/CHmPcFwmFmb9nErvJ4i0+EqJ0kanHI653gYWCiZeIA09evTfjaivy8hF3wdpRJT2dRf1L6EIe8s/r1580VP8Z9LdG2W6v25DN78yZeWrqIbSUlHNmxE78bcQzdMzMTjsID4TC5GZmNFrc4dEiiFoe8LLcXp2FUbzabrN9+8iGBqpLJ1pJiZmxYx9TzL6IkELsdFoBNKUyr8XvriIOflD7EIa9HVlbcXtG10VCdpCEy8q4Ihjj77depCAbjvsduGGS4W1IfENFayIhatHqFvkoen/89Mzesw2N3cPHgI/j1EUPjthqNx75Pn+hkGEqhtY6pQ2s05QmStNtu59z+A2V6nmgQSdSiVasMhTjzzdfIqyivfvj312+/5h9z5+B2ODi+ew9uOvY4OqWlJ7xGKBxOWIsGSHc66ZaRyabiIjqmpnFSz148vfCHesV5Vt/+/N8vZGWgaBhJ1KJVm7pqBYW+yqgZGnt3Dq80TaatWcXsLZuYNflS2nhid+gG+N+mDRiQsPwRsizO6T+QS4cMQ2vN6P88V+84h3fqHHdOthDJkBq1aNW+37ENX4JZFrC3dhzk1WVLE56zZk/8rbX28pkmi37aCcAeXyV7Kivjnldb+eSurz5POBtEiLpIohatWm5GVp0j1UA4zPwd2xNfIzOrep/CeJyGQe822QCkOJwJtwrvmJqWMFlXhkIsz9tda5xCJCKJWrRqFw4+HJuq/a+xTSl6ZmVFHQuYJt9s3czszZsYk5tLqtOZMMlaGiYNGgxEelKf2LNXzA8Hj93O1SOOpk92dtxraODH3ZKoRcNIjVq0ap3S0nn5rHO5adZ08irKq5eC7zvoddpsXDpkWPXXc7dt5befTGPvvA1La/5v9Anc/sVnce9htxm0S0mt/vrBcSdT9MmHLN71Ew7DIBgOc96AQVw06HCW7d7FmoKCuNfZXVG+n59WHKokUYtWb3inznz168vZVV5OyArzwDez+WrzJlDQPiWVh8adXN0zujTg58qPPqDSDEVd456vv0x4/XCNhTBpLhevnXM+m4uL2FlWRp/sHHK8kQeVY3v05IPVK2OWn7ttdrpnyqpE0TBJJWqlVCbwPDCIyGDlN1rruU0ZmBD1oZSiY1oaAP+eeCYVwSA+0yTb40Gpn4saM9avi/t+S2u6Z2aytaQkqoueoRSjunWP+57czCxyM6NLKmNze5Lt9ZJXXh41i8TtsDOxT78GfjpxqEu2Rv0YMENr3Q84AljVdCEJsf9SnE5yvN6oJA1QFgzG9JeGyFzq47p0I93lwl3V5N9jt5PpdnP38eOSvq/DZuPd8y7k6C5dsRsGdsNgSIeOvHvehaQ6Zfsr0TBK1zItCUAplQEsAXrquk6uMnz4cL1gwYJGCE+IxrWmYA9nv/Vada/ovTx2B/856xz6tMnhvVUrWJWfx8B27Tmn/0DSXQ1b9l0ZCmFpLQlaJEUptVBrPTzea8mUPnoA+cBLSqkjgIXADVrriho3mQJMAejWrdv+RSxEE+mbncO5/QYydfXK6jq11+5gTI8eDO/YGaUUvxl6ZKPcq7Ypf0LURzIj6uHA98BxWut5SqnHgFKt9f8leo+MqEVLprXmqy2beGfFcsJac1a//ozvdRhGjTJJaSDAjPVrKQn4OaZLNwa3a99MEYtDwf6OqLcD27XW86q+fhe4tbGCE+JAU0oxJrcnY3J7Jjxn4U87uPSD99AaglYYh2EwrkcvHj3ltJiELkRTq/NhotZ6F7BNKdW36tA4YGWTRiVEMwpbFr/9eBoVoRCVZgjTsvCZJl9s2sjHa1c3d3jiEJTsPOrrgNeUUk5gI3BZ04UkRPP6MW83/hrzrAEqzRBvr1jOGX37H9B4tNYQnIsOfAUqDeU5E2WX50CHkqQStdZ6CRC3diLEwcbSOmZa38+v1XeLgf2jtYUuvg4C3wKVgANd8Rw64wEMz8QDGotoPtLrQ4gaDm/fAXucTQc8dge/HDDowAYT+AwCc4gkaYAQ4IeSO9BWRS1vFAcTSdRC1GA3DJ6YcDoeux2XLfKPTq/dwTFduhz4sofvY8AX+4KyQXD+AY1FNB/p9SFEHCO7duPrS6/ko7WrKfT5GNm1G0d37pKwJNJkVC1zsZV8+x4q5P+0EAlke71RXfeag/Kci/Z/TuyoWoHz6OYISTQDKX0I0ZI5R4L3IsAFuEGlgPKisp4mMglLHApkRC1EC6aUQqX/Ce2dBMFvQaWCayzKSK37zeKgIYlatDg/lZXx6o9LWFtQwNAOHblw0OFkeTxNdr/tpSXc9dXnfLN1C3bD4Iw+/bhj9AmkNbAZU1NQ9u5gj99uVRz86uz10RDS60M01I95u7nwvbcwLYtgOIzLZsfrcDBt0mQ6p6c3+v1KAwHGvvICxX5/dR9qp81G3+wcPrjg4gP/8FAcsmrr9SE1atGi3Pa/mVSGQtVbagXCJiV+Pw/Omd0k95u6eiW+qnakewXDYTYUFbKwaudxIZqblD5Ei+ELhVhTsCfmuIVm9pbNCd+ntWbmhvW8smwxZYEApx7Wh18dPpSUJPpAr8zPw1ejN/Xea64vLGB4p871+gxCNAVJ1KLFsBsGhlKE45TjPI7Ef1Uf+vZrXl22FF9Vf44NhQVMXbWSaRdOxm2vvSd0/5y2eOz2mGStlKJXmzYN+BRCNL5DrvRRuKuIhZ8tZcf6n5o7FFGDw2ZjfK/DcBi2qONum52LBh0R9z27yst4eeni6iQN4A+H2VFWyger694x7pz+A/E4HFGtS502Gz0ysxjeUUbTomVoUYnasiya4uHm3ms/+ttnmNzjd/zl/H8w5Yg/cstJ91JZFmd5rmg29409iUHt2uGxO0h1OnHZ7Izunss1I+Iv7lj00084ayR2AJ9p8uXmTXXeL93l4v3zL2J0t+7YlMJls3FGn368ds758iBRtBgtovSRt20Pj139LAtmLkUZipFnjuD6J68gs21Go93jg8en879XvyEUCBEKREZfy+es4tHfPsvtr93QaPcR+yfd5eK98y9iRd5utpSU0C8nh55ZiUsQOV4v8X6025SiQ2pyc427ZWTy0pnnomvpmidEc2r2RO2vDHDdMbdTvLsYy9IQhu8++IGNSzbzwqpHsdliR0sNMfWxTwhUBqKOhQImc97/nqD/apxuWeXVkgxs156BtWx9tbWkmHtnf8mcrZsJxdlV3GGzMXnwkHrdU5K0aKmavfTx9TtzqSytjCTpKmEzTMGuIt55eBqr56/DivONWF/lJZVxj2sd+WEhWo9CXyVnvfkaX23ZRNCy0IACDKVIdThJczp55KRTOCw7u7lDFaJRNHui3rxiG/6K2ETpLw/wyt3vcMuJ93JRt6tZv6TuemNtho4bjGHEjpjadc0hLUuW47Ymby7/EZ9pRs191kRmjdw37iR+uPIaJhzWN/EFhGhlmj1R9zy8O55Ud9zXQoEQvnI/BTsL+dNJ9xIMxG6PlKwrH5qMN8OLwxWp9hg2A5fXxY3PXiX/5G1llu3eRSAcO/fZYRgYRGZtCHEwafZE/YtfHkNqVgo2e+2hmMEwC2YsafB9OvZsz/PL/8k5vz+NQaP6Mf6yMTz5w0MMGXOAd+wQ+21A23a44iRjS2t6ZGY1Q0RCNK1mf5jodDt5/PsHeer3L/H9RwswzTCWGVuTtiyL0sLy/bpXdscsrnhwcsLXNy3fysz/fEllqY/jzjqKEacMwYizJZNoXhcOOpznFy8gULXMHMBp2BjQtl2tDyCFaK1aXFOmb96fx98ufQJ/uT/quNPt4PkV/6Rjj8TfiBUlFcx6ZTbrF2+i1xG5nPzrE0jNTEnqvh8/M4un//AyZtDEClu4U1wMHTeYu9+/WZJ1C7SmYA93fvEZi3f9hN0wOL1PX+46fhypSSwbF6Ilqq0pU4tL1GEzzB/H3s36RZuqZ2O4U1xMuHwc1zx6WcL3/bRpN9cdfRv+yiCBygAurxOXx8UT8x6kY8/aR1mlhWVc2OUqgv7oGrg71c1t/72ekWeOaNBnEU3PtCwMpaJWFgrRGrWq7nk2u42//e/PXP3oZRxxwkCOPm0Yt7/+e67+56W1vu+J616grLC8eq50oDJIWVE5/7rmuepzgoEQq+evY/va6K5oiz9fjs0RW/P0l/uZ/c53+/+hRJPZ2x9EiINZs9eo43E4HZx6xThOvWJc0u9Z+NmyqLnYANrSLPr8R7TWfP76Nzx+zfOgIBwK07lPR/4y7Vbadc3B5XGirfj/sti6cvt+fRYhhNhfLW5EnYwNSzfz118/zg2j7uTFO16nKK8Ee4LuanaHjXWLNvLoVc9QWeajstRHwBdk8/Jt3Dr+L2itGXbiYEKB2OleAFtWbcdX4Y/7mhBCHAgtJlGbIZONy7aQtzW/1vPmfbKQG0bewRevfcPK79bw7j8+4opBNzLyzOHVc6T3stltnDDpOD54YnpM/dkKW+RvK2Dtwo043U7Ss+MverE77eRvK9i/DyeEEPuhRZQ+vnrrWx69+lmssEU4FKbX0B7c/d4fadMhek6sZVn8Y8ozBHzB6mOhgIkVrsAwDOxOe9TI2LIsDEORt7UgbmnDZjcozisBoNeQXBbMXBpzTjgUJqez9CUWQjSfZh9Rr1u0kYcvf4qK4kp8ZX6C/hBrf1jP7RMeiDl3z/YCKoorYo6HTYv50xfHrVF/8foc+ozojcsTO20r6Dfpd1RvAC7583m4vNHnuLxOJlwxDm9a022sKoQQdWn2RP3+Y5/ElCXCpsWO9T+xcdmWqOPedG/iBk1aE4jTM0QZiuwOmWR3ysLp/nm3D3eKi0m3nkVGTmTD1AHH9uWud/9Ip94dUIbCk+bmnN+flnC2ia/Cz5M3vMjZbS7l9NTJ3Hv+I+RvlxKJEKLxNXvpI2/rnrhlCcNuo+CnInoe3r36WGpmCkeePIQFM5dgBn8ucbi8LgaN7s/86YsIh6ITuWGzkd05m6cW/JUPnpjOnPfnk56dxtnXn8oxE4+MOnfEKUN5ee3jhIIh7A57wh4gWmtuHX8f6xZurO5t/e3U+ayYs5qX1vxLRuBCiEaV1IhaKbVZKfWjUmqJUqphK1kSGHHKUJye2H3tzECIvsN7xRz/08vX0v/ow3B5nKRkeHG6HUy86iR++YeJMUkaAMvi6FOHkpKRwsV3/JKnF/6Nv876v5gkvS+H01Fro6ZV89axcenm6iQNkYeTlWU+Pn/16zo+sRBC1E99RtRjtNaxW0Tvp4lXncRHT8+kaHdx9YNAd4qLc26cSHp2Wsz5qZkp/GP2vWxfu5P87QX0GNyNzLYZPDj5MZRSMVt5OdwOXr77LWa8+CVhM8zIM0Zw3ROX40lt+Kh38/JtxNtWxF8RYO2CDQ2+rhBCxNPspY/UzBSeXvg33nlkGt99+APp2Wmcc8NpjDon/h55e3Xp04kufTpVf7348+Vx91ssK6zg7b9Nq/76s1dmM2fqfN7e9Rxuj6vO+IrySvj437NYu3ADvYb04PTfnkznwyJ17JpcXie5g7vVeU0hhKiPpHp9KKU2AUVExpHPaK2fjXPOFGAKQLdu3Y7csmVLzVOa1BWDb2TLiuRXEY6/9AT++OLvoo5tWr6VF29/nZVz19KmYybjLx3Da/e9R9AfJOgP4XA5cLjsPDrnPh68+DG2rd6BGYp0cFNKkZLp5ZX1T8hGBEKIetvvpkxKqc5a6x1KqXbAZ8B1WuuExdj9acrUUDP/8yVPXPdC1G4xhs3ACsefJeJJc/Pu7heq90rcunoHvzvqVgIVfvb+kRiGipnyBzB4dH/unnoz/7rmeeZMnYcOawaO6suNz1xF176dG//DCSEOeo3aPU8pdTdQrrV+ONE5zZGotda8eMfrvP/oJzhcDkKBEDmds9m5YVfC93jTPPzplesYeeYI7pv0T75+d27Cnh81HXHCAK59/Aq69uuEtnTCJexCCJGM/eqep5RKUUql7f1v4GRgeeOGuP+UUgw/eQgjTh1Gmw6ZONyOWpM0QGWZjwcuepRdm/NYPW9d0kkaYOlXK7nhuDso/KlYkrQQokklk2HaA1OrpqvZgde11jOaNKoGeO2+d3n9wakE91lenoxwOMysl7+iY8927N5Se5+RmkL+EB8+MZ0rHkq8a4wQQuyvOhO11nojcMQBiAWAbz+Yz/uPfkJZYTkjzxrBuTdOrPPhXOGuIl69772oRTDJMoNhivNLueiOc1k5d23MKsnahIImaxdurPc9hRCiPpp9Cfm+/nPXmzx0yb9Y9vVKNi3fytt//5Crh91CRWllre9b+tXKhA8N6+JwOzh6wlCGjh3M7/89BRKtc4lz3O6003tojwbdVwghktViEnXJnlLe/tu0qFkboYBJcV4Jnzz7v1rfa3faG5yozYDJkeOHADBoVH9S0r0x57hTXAwa1S+qVwiAw+XgrGtPadB9hRAiWS0mUa9dsCEmEQIEfEF+mL641vf22I9FJlprNizZTMAf5PqRt1NREjt6P+u6CTw0404mXDEOl9eFMhQDR/bln1/fS7tubRt8byGESEaLma6Q1T6TsBmOOa4MRduu2bW+9+W73mr4jRW8W7UqMlF9+s2HPiB/eyFX/+PXXPuvy9Fa19oLRAghGlOLGVH3GpJLh9x2GLbokJwuB2dff2rC9wV8Aea8P6/B91XA3I8W1PkQ8au3vuWG4+4kbIYlSQshDqgWk6iVUjw44w4OG9YDp8eJN81DSoaXPzx/NYcN65nwfQFfMG6DpH0ZNgObw4ZhN+IctxOorHtKXzgUZtem3Xz7QcN/KAghREO0mNIHQE7nbJ6Y9xA/bdpNeVEFuYO64nDG1q33lZaVSrtuOXEXt3Tq3YFrH7+cdt1yyMhJw5Pq5v3HPuXbqfNp1y2Hib89mdtOuS/p+MKmxfO3vs4vfjmy3p9NCCEaqt5LyJNxoJaQr5y7hv+9+jX52wpY9NkyQiETbWkcLjsur4unfvgrHXu2j/vevK35vPXwNKY9OaPOEXlNVz18Cb/8wxmN8AmEECKitiXkLWpEXR8v3PYaUx+fXrUSUeNwO+natxPp2WkMPK4vZ19/Gtkds+K+d9uaHVx79G2RqYCJkrQi4Wuv3P0OZ147oc7RvhBCNIZWmai3rdnB+//6NGq5eNAXZPeWfG797/W11rQBnrn5v/jK/HH7VwM4XHay2meStzX+PgmWZZG/rYBOvTrUGeuWVdtZOGsp3nQvo84+itTMlDrfI4QQ+2qViXreJ4vQcRa4hPwhvv94YdxEvXe+dGlhOctmr0iYpCGy0KZwV3HC1y1Lk9E2vdYYtdY8ecOLTH/hC7SlsdkNnrz+Be798E8MHTu41vcKIcS+WmWidnmcMdP4ILIhrsvjjDm+a3Met51yP3t2FGDYDHzl/jrvkahviMvj5PjzR8ZdwbivBbOWMvOlL6tH/aGqBZf3nPswb+96HqdLyiZCiOS0mOl59THq3GPilo8Nm8EJF0TPyNBac/uE+9m5/if8FQEqS331fnho2AxcHidOt4OxF43ihn9PqfM9M//zZdRy+H3jWTZ7Zf0CEEIc0lrliDqrXQa3vXo9D13yr+qRdThkceOzV8Us6d6wdDP52wvi7tSiDIU3zUPQF6Rdblt2b86PO5Lu2rcTD0y/g7Q2qXhS3EnFaMVZZblXvBWYQgiRSKtM1ACjzj6at3Y+xw/TF2NZmhGnDInbDrWssDxumQTAm+pm3MWjOeOa8VhaM+Xwm2LOsdltjL14NO265tQrvrEXjeaHGUtiRtVW2OKIEwbW61pCiENbq03UACnpXk644Lhaz+k7onfC5eEVpT5mvvQl8z9dTM8huXHPsSyLiVedVO/YRp45gqNPG8a8TxbhrwjgcNoxbAa3vHwdbm/du58LIcRerTpRJ8Od4sLpdiR8OBjwBSn4qZDSwrK4tWunx0npnjLS26TV676GYXDHGzeyfM5q5n26iLSsFMZcOKreI3MhhDjoE/WeHYWEQ7XXhEMBE8Nmi/uaZVpktc9o0L2VUgwe3Z/Bo/s36P1CCAGtdNZHfaSke7CsujcV6NizHS5v9NQ+p8fJ2ItGkZIhi1SEEM2nRSXqPTsKePjypzi/4xVc1u96PnxqRlJJtjYpGSmMOGUoDmfifzy4U1xc8ufzuPHZ35LRNh2n24HDZeeoCUOYdOvZ+3V/IYTYXy2mKVPJnlKuGHgjZUXlhM1IcnZ5XYy7eDQ3PnPVfsVTUVLBXWf/nVXz1mGzRxa82KoWx4SCJufccBqXP3ARSiksy+K9Rz/mv3e/g1IKM2TSZ0Rv7nr3JjLbNqwEIoQQdamtKVOLSdSv/uUd3nhwaswMDYfbwSvrHienc+27vCRj54Zd5G8vIHdgV3ZtymPa0zP57sMfKC+qoEvfTlzzz0txeV3cfur9UT2q7Q4bfUb05rE5ybdEFUKI+qgtUbeY0seyr1fFnUbndDnYsGTzfl1ba83yOatYPX89OZ3bkJGTzvefLGT223MpL6oAYPuandxz7sO8ePvrMRsJmKEw6xdvitvzWgghmlqLmfXR5bCOLP1qRcxu4mbIpF33hm8gu2dnITePu4eCHYWgFOGQyXFnH813H86PScgBX5ANy7bEvY7dYaNod0lSHfOEEKIxtZgR9VnXn4rDFf1zw+600/PwXHoMavgu4w9c9Cg71+/CV+7HV+Yj6A/x3QfzMUPx51Xv3XigpnAoTM/DGx6HEEI0VItJ1N36debeD2+lXfe2ON0O7E47w8cP4b6Pb23wNYvySlg9b33MKD3gC2KZ8WvzvYfmkpqVin2fWSJur4tL/zIJT6qnwbEIIURDtZjSB8CwcYN5deOTFO4qxp3iqrOVaF2CviCGEX/HcG+6BzMUJlD5cy8Ol8fJFQ9NpvNhHXnn4WnMn76IrPaZnHfTGRw1Yeh+xSKEEA3VYmZ9NKa8bXuY+Z8vKdhRyJz351GypyzqdbvTzhlXj6dDz3a8+eBUivNL6T6gC7995NcMO/HwZopaCHEoOyj3TExkwayl3H3O37HCYUIBE6fHiTIUNruBGQzj9rrIaJvOxXeeS3p2Gmdfd2pzhyyEELU6qBJ12Azz4MWPRZUzgr4gTreDgSP7ktYmlSNOGMRJv/qF1JuFEK1G0olaKWUDFgA7tNYTmy6khtuwdDOhYOxc7KA/REWpj7/9765miEoIIfZPfWZ93ACsaqpAGoPD5UDH2ckFwOmWPQqFEK1TUolaKdUFOA14vmnD2T+5A7vGbUnqTnEx8aqTmyEiIYTYf8mOqB8FbgEStrJTSk1RSi1QSi3Iz89vlODqSynFPR/8ifScNLxpHlxeJ06Pk+PPO5YxF9a+E4wQQrRUddaolVITgTyt9UKl1AmJztNaPws8C5HpeY0WYT31GNSNN7c/w/xPF1OcV8LgXwygW7/OzRWOEELst2QeJh4HnKGUOhVwA+lKqVe11pObNrSGczgdHHfWUc0dhhBCNIo6Sx9a69u01l201rnAJOCLlpykhRDiYNNien0IIYSIr14LXrTWXwFfNUkkQggh4pIRtRBCtHCSqIUQooVrku55Sql8IP5WKY0rB9hzAO5zoMnnal3kc7UuLfVzdddax93OqkkS9YGilFqQqC1gayafq3WRz9W6tMbPJaUPIYRo4SRRCyFEC9faE/WzzR1AE5HP1brI52pdWt3natU1aiGEOBS09hG1EEIc9CRRCyFEC9eqE7VS6jyl1AqllKWUalXTbeJRSp2ilFqjlFqvlLq1ueNpLEqpF5VSeUqp5c0dS2NRSnVVSn2plFpZ9XfwhuaOqTEopdxKqflKqaVVn+ue5o6pMSmlbEqpxUqpj5s7lvpo1YkaWA6cA3zd3IHsr6o9KZ8EJgADgAuVUgOaN6pG8x/glOYOopGZwE1a6wHAMcDvDpL/XwFgrNb6CGAIcIpS6phmjqkxtfgtBeNp1Ylaa71Ka72mueNoJEcB67XWG7XWQeBN4MxmjqlRaK2/BgqbO47GpLX+SWu9qOq/y4h887f6SUwd7AAAAZlJREFUHSp0RHnVl46qXwfFjIPWsqVgPK06UR9kOgPb9vl6OwfBN/6hQCmVCwwF5jVvJI2jqjywBMgDPtNaHxSfiyS2FGypWnyiVkr9Tym1PM6vg2K0KVo3pVQq8B7we611aXPH0xi01mGt9RCgC3CUUmpQc8e0v/bdUrC5Y2mIevWjbg5a6xObO4YDZAfQdZ+vu1QdEy2UUspBJEm/prV+v7njaWxa62Kl1P+3d4coFUVRFIb/vwg2i8FoEMcgNsFicwAmq2NxBmbBKBgehhcNFhFEB/CGIWzDfcFi0QvnHN/64MKNKy027HvZS6b9wuiL4OFOCn7X/US9QZ6BA3Vf3WI6e3bfOFP8QBW4Ad6r6rp1nrmou+rO+n0bOAU+2qb6u9FPCg5d1Oq5ugKOgAd10TrTb1XVJ3AFLJgWU3dV9dY21TzUW+AJOFRX6mXrTDM4Bi6AE/Vl/Zy1DjWDPWCpvjIND49VNdSnbP9RfiGPiOjc0BN1RMQmSFFHRHQuRR0R0bkUdURE51LUERGdS1FHRHQuRR0R0bkvZgorEEMrAbEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28J-QlUZmpnv"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpZxuxo0mqjF"
      },
      "source": [
        "%tensorboard --logdir /tmp/autoencoder"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}